{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3ZcgJ4lkp4Bpa+ZC0foeL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phuocnguyen90/Random-projects/blob/main/Receipt_OCR_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Install system dependencies for Tesseract OCR and PDF processing\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install tesseract-ocr tesseract-ocr-vie poppler-utils -y\n",
        "\n",
        "# Install Python libraries\n",
        "!pip install streamlit pyngrok pytesseract pdf2image paddleocr paddlepaddle openai gspread google-auth python-dotenv llama-parse Pillow -q\n",
        "\n",
        "# Pillow is usually pre-installed, but explicit install ensures it's there.\n",
        "# Use paddlepaddle (CPU) for simplicity in Colab unless you have a GPU runtime and want GPU acceleration (paddlepaddle-gpu)\n",
        "# llama-parse is used here as an example API parser. Replace/add others if needed.\n",
        "# openai is used for the LLM extraction part. Replace/add others (e.g., anthropic, google-generativeai) if needed."
      ],
      "metadata": {
        "id": "_UZOTZtbv2VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Get AND Validate Credentials before writing .env\n",
        "\n",
        "import os\n",
        "import json\n",
        "from getpass import getpass\n",
        "import gspread\n",
        "from google.oauth2.service_account import Credentials\n",
        "from google.auth.exceptions import DefaultCredentialsError\n",
        "import openai\n",
        "import sys # To check if running in Colab\n",
        "\n",
        "print(\"--- Credential Input ---\")\n",
        "print(\"Please enter your details below.\")\n",
        "print(\"NOTE: Ensure Cell 1 (Installations) has finished and you have uploaded your Google Service Account JSON file.\")\n",
        "\n",
        "# --- 1. Get User Inputs ---\n",
        "openai_api_key = getpass('Enter your OpenAI API Key (leave blank if not using): ')\n",
        "llamaparse_api_key = getpass('Enter your LlamaParse API Key (optional, leave blank if not using): ')\n",
        "ngrok_auth_token = getpass('Enter your NGROK Auth Token (leave blank if not using): ')\n",
        "google_sheet_name = input('Enter the exact name of your Google Sheet: ')\n",
        "google_creds_path = input('Enter the path to your Google Service Account JSON key file (e.g., \"my-google-creds.json\"): ')\n",
        "\n",
        "# --- 2. Perform Validations ---\n",
        "print(\"\\n--- Credential Validation ---\")\n",
        "\n",
        "# Flags to track success\n",
        "openai_ok = False\n",
        "llamaparse_provided = bool(llamaparse_api_key) # Just track if provided, full validation is hard here\n",
        "gsheet_name_ok = False\n",
        "gcreds_file_ok = False\n",
        "gcreds_valid_format = False\n",
        "gsheet_access_ok = False\n",
        "apis_enabled_ok = True # Assume okay initially, check during gsheet access\n",
        "\n",
        "# --- OpenAI Key Check ---\n",
        "if openai_api_key:\n",
        "    print(\"Checking OpenAI API Key...\")\n",
        "    try:\n",
        "        # Simple test: List models (low cost)\n",
        "        temp_client = openai.OpenAI(api_key=openai_api_key)\n",
        "        temp_client.models.list()\n",
        "        openai_ok = True\n",
        "        print(\"✅ OpenAI API Key seems valid.\")\n",
        "    except openai.AuthenticationError:\n",
        "        print(\"❌ ERROR: OpenAI API Key is invalid (AuthenticationError).\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ WARNING: Could not fully validate OpenAI key ({type(e).__name__}). Check connectivity or key later.\")\n",
        "        # We might still proceed but warn the user\n",
        "else:\n",
        "    print(\"ℹ️ INFO: OpenAI API Key not provided. LLM extraction will be disabled.\")\n",
        "    openai_ok = True # Treat as 'ok' in terms of not blocking .env creation\n",
        "\n",
        "# --- LlamaParse Key Check (Basic) ---\n",
        "if llamaparse_provided:\n",
        "    # Hard to validate without making a real parsing call. Just acknowledge.\n",
        "    print(\"ℹ️ INFO: LlamaParse API Key provided (basic check only).\")\n",
        "else:\n",
        "    print(\"ℹ️ INFO: LlamaParse API Key not provided. LlamaParse option will be disabled.\")\n",
        "\n",
        "# --- Google Sheet Name Check ---\n",
        "if google_sheet_name and google_sheet_name.strip():\n",
        "    gsheet_name_ok = True\n",
        "    print(f\"✅ Google Sheet Name provided: '{google_sheet_name}'\")\n",
        "else:\n",
        "    print(\"❌ ERROR: Google Sheet Name cannot be empty.\")\n",
        "\n",
        "# --- Google Credentials File Existence Check ---\n",
        "# Check if running in Colab or similar environment where path matters directly\n",
        "is_colab = 'google.colab' in sys.modules\n",
        "if is_colab and not google_creds_path.startswith('/content/'):\n",
        "     print(f\"⚠️ WARNING: Credential path '{google_creds_path}' doesn't start with '/content/'. Ensure it's the correct path in the Colab file browser.\")\n",
        "\n",
        "if os.path.exists(google_creds_path):\n",
        "    gcreds_file_ok = True\n",
        "    print(f\"✅ Google Credentials file found at: '{google_creds_path}'\")\n",
        "\n",
        "    # --- Google Credentials Format and Auth Check ---\n",
        "    print(\"Checking Google Credentials and Sheet access...\")\n",
        "    try:\n",
        "        scopes = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "        creds = Credentials.from_service_account_file(google_creds_path, scopes=scopes)\n",
        "        gcreds_valid_format = True\n",
        "        print(\"✅ Google Credentials file format seems valid.\")\n",
        "\n",
        "        # --- Google Sheet Access Check ---\n",
        "        try:\n",
        "            client = gspread.authorize(creds)\n",
        "            # Try opening the sheet - this checks sharing and sheet existence\n",
        "            spreadsheet = client.open(google_sheet_name)\n",
        "            # Optionally, try accessing a property to be more certain\n",
        "            _ = spreadsheet.sheet1.title\n",
        "            gsheet_access_ok = True\n",
        "            print(f\"✅ Successfully accessed Google Sheet: '{google_sheet_name}'\")\n",
        "\n",
        "        except gspread.exceptions.SpreadsheetNotFound:\n",
        "            print(f\"❌ ERROR: Google Sheet '{google_sheet_name}' not found. Check the name and ensure it's shared with the service account email: {creds.service_account_email}\")\n",
        "        except gspread.exceptions.APIError as e:\n",
        "            apis_enabled_ok = False # Mark API enablement as failed\n",
        "            if 'insufficient authentication scopes' in str(e) or '403' in str(e):\n",
        "                 print(f\"❌ ERROR: Google API Error (403 - Likely scopes/permissions). Ensure 'Google Sheets API' and 'Google Drive API' are ENABLED in your Google Cloud project.\")\n",
        "                 print(f\"Service account email: {creds.service_account_email}\")\n",
        "            else:\n",
        "                 print(f\"❌ ERROR: Google API Error accessing sheet: {e}\")\n",
        "                 print(f\"Service account email: {creds.service_account_email}\")\n",
        "        except Exception as e: # Catch other potential gspread errors\n",
        "            print(f\"❌ ERROR: Failed to authorize or access Google Sheet: {e}\")\n",
        "            print(f\"Service account email: {creds.service_account_email if 'creds' in locals() else 'N/A'}\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError: # Should not happen if os.path.exists passed, but belt-and-suspenders\n",
        "        print(f\"❌ ERROR: Google Credentials file disappeared after initial check? Path: '{google_creds_path}'\")\n",
        "        gcreds_file_ok = False # Correct flag\n",
        "    except (json.JSONDecodeError, ValueError) as e: # Catch bad JSON format or structure issues\n",
        "        print(f\"❌ ERROR: Google Credentials file is not valid JSON or has incorrect structure: {e}\")\n",
        "    except DefaultCredentialsError as e:\n",
        "        print(f\"❌ ERROR: Google Authentication failed. Could not find credentials: {e}\")\n",
        "    except Exception as e: # Catch-all for other credential loading issues\n",
        "        print(f\"❌ ERROR: Failed to load Google Credentials: {e}\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ ERROR: Google Credentials file not found at '{google_creds_path}'. Please upload it and ensure the path is correct.\")\n",
        "    # Ensure subsequent checks depending on the file don't run implicitly\n",
        "\n",
        "# --- 3. Decide and Write .env File ---\n",
        "print(\"\\n--- Summary & .env Creation ---\")\n",
        "\n",
        "# Define essential checks for writing the .env file\n",
        "# We MUST have the GSheet name and a valid-looking, accessible GCreds file + sheet access\n",
        "essentials_ok = gsheet_name_ok and gcreds_file_ok and gcreds_valid_format and gsheet_access_ok and apis_enabled_ok\n",
        "\n",
        "if essentials_ok:\n",
        "    print(\"✅ All essential Google credentials validated successfully.\")\n",
        "    if not openai_ok and openai_api_key:\n",
        "        print(\"⚠️ WARNING: OpenAI API Key validation failed or was skipped. LLM features might not work.\")\n",
        "\n",
        "    try:\n",
        "        with open(\".env\", \"w\") as f:\n",
        "            if openai_api_key: # Only write if provided\n",
        "                f.write(f\"OPENAI_API_KEY={openai_api_key}\\n\")\n",
        "            if llamaparse_api_key: # Only write if provided\n",
        "                f.write(f\"LLAMAPARSE_API_KEY={llamaparse_api_key}\\n\")\n",
        "            if ngrok_auth_token:\n",
        "                f.write(f\"NGROK_AUTH_TOKEN={ngrok_auth_token}\\n\")\n",
        "            f.write(f\"GOOGLE_SHEET_NAME={google_sheet_name}\\n\")\n",
        "            f.write(f\"GOOGLE_CREDS_PATH={google_creds_path}\\n\")\n",
        "        print(\"✅ .env file created successfully.\")\n",
        "        print(\"You can now proceed to run Cell 3 (Write app.py) and Cell 4 (Run Streamlit).\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERROR: Failed to write .env file: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ ERROR: Essential credential validation failed. Cannot write .env file.\")\n",
        "    print(\"Please review the errors above, correct the inputs or configurations (like API enablement or sheet sharing), and rerun this cell.\")\n",
        "    if not gsheet_name_ok: print(\"   - Issue: Google Sheet Name missing.\")\n",
        "    if not gcreds_file_ok: print(\"   - Issue: Google Credentials file path incorrect or file missing.\")\n",
        "    if gcreds_file_ok and not gcreds_valid_format: print(\"   - Issue: Google Credentials file format invalid.\")\n",
        "    if gcreds_valid_format and not apis_enabled_ok: print(\"   - Issue: Google Sheets/Drive API likely not enabled in Cloud project.\")\n",
        "    if gcreds_valid_format and apis_enabled_ok and not gsheet_access_ok: print(\"   - Issue: Google Sheet not found or not shared correctly with service account.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzWjmDrcv-hA",
        "outputId": "4fb1e1be-293a-48de-c3a0-3f606e5eba36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Credential Input ---\n",
            "Please enter your details below.\n",
            "NOTE: Ensure Cell 1 (Installations) has finished and you have uploaded your Google Service Account JSON file.\n",
            "Enter your OpenAI API Key (leave blank if not using): ··········\n",
            "Enter your LlamaParse API Key (optional, leave blank if not using): ··········\n",
            "Enter the exact name of your Google Sheet: receipt\n",
            "Enter the path to your Google Service Account JSON key file (e.g., \"my-google-creds.json\"): /content/elite-height-454109-g4-33c0427ef366.json\n",
            "\n",
            "--- Credential Validation ---\n",
            "Checking OpenAI API Key...\n",
            "✅ OpenAI API Key seems valid.\n",
            "ℹ️ INFO: LlamaParse API Key provided (basic check only).\n",
            "✅ Google Sheet Name provided: 'receipt'\n",
            "✅ Google Credentials file found at: '/content/elite-height-454109-g4-33c0427ef366.json'\n",
            "Checking Google Credentials and Sheet access...\n",
            "✅ Google Credentials file format seems valid.\n",
            "✅ Successfully accessed Google Sheet: 'receipt'\n",
            "\n",
            "--- Summary & .env Creation ---\n",
            "✅ All essential Google credentials validated successfully.\n",
            "✅ .env file created successfully.\n",
            "You can now proceed to run Cell 3 (Write app.py) and Cell 4 (Run Streamlit).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ASc1NpEiwY4",
        "outputId": "4c1c9f63-07d2-42bb-8b91-2d08d9c39b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_bytes\n",
        "from paddleocr import PaddleOCR\n",
        "import openai\n",
        "import gspread\n",
        "from google.oauth2.service_account import Credentials\n",
        "from llama_parse import LlamaParse # Example API Parser\n",
        "from dotenv import load_dotenv\n",
        "import io\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np # Paddle requires numpy\n",
        "import asyncio # For potential async needs like LlamaParse\n",
        "\n",
        "# --- Page Config MUST BE THE FIRST STREAMLIT COMMAND ---\n",
        "st.set_page_config(layout=\"wide\") # <-- MOVED HERE\n",
        "\n",
        "# --- Configuration & Initialization ---\n",
        "load_dotenv() # Load environment variables from .env file\n",
        "\n",
        "# Get credentials from environment variables\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "LLAMAPARSE_API_KEY = os.getenv(\"LLAMAPARSE_API_KEY\")\n",
        "GOOGLE_SHEET_NAME = os.getenv(\"GOOGLE_SHEET_NAME\")\n",
        "GOOGLE_CREDS_PATH = os.getenv(\"GOOGLE_CREDS_PATH\")\n",
        "NGROK_AUTH_TOKEN = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "# --- Helper Functions (Updated for Vietnamese) ---\n",
        "# Define functions before they are called during initialization if needed\n",
        "\n",
        "def process_image_tesseract(image_bytes):\n",
        "    \"\"\"Performs OCR on image bytes using Tesseract for Vietnamese.\"\"\"\n",
        "    try:\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        # Use 'vie' for Vietnamese language pack\n",
        "        text = pytesseract.image_to_string(image, lang='vie')\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Tesseract OCR failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_pdf_tesseract(pdf_bytes):\n",
        "    \"\"\"Converts PDF to images and performs OCR using Tesseract for Vietnamese.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        images = convert_from_bytes(pdf_bytes)\n",
        "        for i, image in enumerate(images):\n",
        "            st.write(f\"Processing PDF page {i+1} with Tesseract (Vietnamese)...\")\n",
        "            # Use 'vie' for Vietnamese language pack\n",
        "            text += pytesseract.image_to_string(image, lang='vie') + \"\\n\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Tesseract PDF processing failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_image_paddle(image_bytes, paddle_ocr_instance):\n",
        "    \"\"\"Performs OCR on image bytes using PaddleOCR (already configured for Vietnamese).\"\"\"\n",
        "    if paddle_ocr_instance is None:\n",
        "        st.error(\"PaddleOCR is not initialized.\")\n",
        "        return None\n",
        "    try:\n",
        "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "        image_np = np.array(image)\n",
        "        result = paddle_ocr_instance.ocr(image_np, cls=True)\n",
        "        text = \"\"\n",
        "        if result and result[0]:\n",
        "            for line in result[0]:\n",
        "                # line[1][0] is the recognized text\n",
        "                text += line[1][0] + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"PaddleOCR failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_pdf_paddle(pdf_bytes, paddle_ocr_instance):\n",
        "    \"\"\"Converts PDF to images and performs OCR using PaddleOCR (already configured for Vietnamese).\"\"\"\n",
        "    if paddle_ocr_instance is None:\n",
        "        st.error(\"PaddleOCR is not initialized.\")\n",
        "        return None\n",
        "    text = \"\"\n",
        "    try:\n",
        "        images = convert_from_bytes(pdf_bytes)\n",
        "        for i, image in enumerate(images):\n",
        "            st.write(f\"Processing PDF page {i+1} with PaddleOCR (Vietnamese)...\")\n",
        "            image_np = np.array(image.convert(\"RGB\"))\n",
        "            result = paddle_ocr_instance.ocr(image_np, cls=True)\n",
        "            if result and result[0]:\n",
        "                for line in result[0]:\n",
        "                    text += line[1][0] + \"\\n\"\n",
        "            text += \"\\n\\n\" # Add separator between pages\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"PaddleOCR PDF processing failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_file_llamaparse(file_bytes, filename, parser_instance):\n",
        "    \"\"\"Uses LlamaParse API to extract text from image or PDF.\"\"\"\n",
        "    if parser_instance is None:\n",
        "        st.error(\"LlamaParse API key not found or parser not initialized.\")\n",
        "        return None\n",
        "    try:\n",
        "        temp_filepath = f\"./temp_{filename}\"\n",
        "        with open(temp_filepath, \"wb\") as f:\n",
        "            f.write(file_bytes)\n",
        "\n",
        "        # Using asyncio properly within Streamlit can be tricky.\n",
        "        # This approach tries to get/create an event loop.\n",
        "        try:\n",
        "            loop = asyncio.get_event_loop()\n",
        "        except RuntimeError:\n",
        "            loop = asyncio.new_event_loop()\n",
        "            asyncio.set_event_loop(loop)\n",
        "\n",
        "        documents = loop.run_until_complete(parser_instance.aload_data(temp_filepath))\n",
        "\n",
        "        os.remove(temp_filepath) # Clean up temp file\n",
        "        if documents:\n",
        "            return documents[0].text # Assuming result is a list of documents\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"LlamaParse API call failed: {e}\")\n",
        "        # Ensure cleanup even on failure\n",
        "        if 'temp_filepath' in locals() and os.path.exists(temp_filepath):\n",
        "            os.remove(temp_filepath)\n",
        "        return None\n",
        "\n",
        "def extract_data_with_llm(text):\n",
        "    \"\"\"Uses OpenAI's LLM to extract structured data from Vietnamese receipt text.\"\"\"\n",
        "    if not OPENAI_API_KEY:\n",
        "        st.error(\"OpenAI API Key not configured.\")\n",
        "        return None\n",
        "    if not text or not text.strip():\n",
        "        st.warning(\"No text provided for extraction.\")\n",
        "        return None\n",
        "\n",
        "    # Updated prompt for Vietnamese context\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert assistant specialized in extracting information from Vietnamese receipts.\n",
        "    The following text was extracted from a receipt, likely in Vietnamese.\n",
        "    Extract the key information and format the output as a single JSON object.\n",
        "    Use the exact English keys provided below. If a value is not found, use null or an empty string \"\".\n",
        "\n",
        "    Keys to extract:\n",
        "    - 'buyer_name': Name of the customer/buyer (Tên khách hàng).\n",
        "    - 'buyer_address': Address of the customer/buyer (Địa chỉ khách hàng).\n",
        "    - 'buyer_contact': Phone number or email of the customer/buyer (SĐT/Email khách hàng).\n",
        "    - 'receipt_date': Date the receipt was issued (Ngày hóa đơn). Format this as YYYY-MM-DD. If the date is like DD/MM/YYYY or DD-MM-YYYY, convert it.\n",
        "    - 'store_name': Name of the store/vendor (Tên cửa hàng / Đơn vị bán).\n",
        "    - 'store_address': Address of the store/vendor (Địa chỉ cửa hàng).\n",
        "    - 'total_amount': The final total amount paid (Tổng cộng / Tổng thanh toán). Provide only the numerical value, removing currency symbols like 'đ' or 'VND' and thousand separators like '.' or ','.\n",
        "    - 'items': A list of items purchased. Each item MUST be an object with 'description' (Tên hàng / Mô tả), 'quantity' (Số lượng - SL), and 'price' (Đơn giá or Thành tiền). Extract numerical values for quantity and price.\n",
        "\n",
        "    Important Notes:\n",
        "    - The text is in Vietnamese. Pay attention to Vietnamese names, addresses, and date formats (DD/MM/YYYY).\n",
        "    - For 'total_amount', 'quantity', and 'price', extract only numbers. Handle separators (like '.' for thousands in VND) correctly. For example, '50.000 đ' should become 50000.\n",
        "    - Output only the JSON object, nothing else before or after it.\n",
        "\n",
        "    Receipt Text (Vietnamese):\n",
        "    ---\n",
        "    {text}\n",
        "    ---\n",
        "\n",
        "    JSON Output:\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-4o\", # Consider GPT-4o or GPT-4 Turbo for better Vietnamese understanding\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert receipt data extraction assistant specializing in Vietnamese documents.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            response_format={\"type\": \"json_object\"}, # Enforce JSON output\n",
        "            temperature=0.1, # Lower temperature for more deterministic output\n",
        "        )\n",
        "        content = response.choices[0].message.content\n",
        "        extracted_data = json.loads(content)\n",
        "        return extracted_data\n",
        "    except json.JSONDecodeError:\n",
        "        st.error(f\"LLM returned invalid JSON. Raw content:\\n```\\n{content}\\n```\")\n",
        "        return {\"raw_llm_output\": content} # Return raw content for debugging\n",
        "    except Exception as e:\n",
        "        st.error(f\"OpenAI API call failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# Find this function within %%writefile app.py\n",
        "\n",
        "def connect_to_gsheet():\n",
        "    \"\"\"Connects to Google Sheet using service account credentials.\"\"\"\n",
        "    if not GOOGLE_CREDS_PATH or not GOOGLE_SHEET_NAME:\n",
        "        # Use st.toast for less intrusive messages if preferred\n",
        "        st.error(\"Google Sheet name or credentials path not configured.\")\n",
        "        return None, None\n",
        "    try:\n",
        "        if not os.path.exists(GOOGLE_CREDS_PATH):\n",
        "             st.error(f\"Google credentials file not found at: {GOOGLE_CREDS_PATH}. Please upload it to the Colab environment.\")\n",
        "             return None, None\n",
        "\n",
        "        # --- THIS IS THE LINE TO CHANGE ---\n",
        "        scopes = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"] # <-- ADDED DRIVE SCOPE\n",
        "        # --- END OF CHANGE ---\n",
        "\n",
        "        creds = Credentials.from_service_account_file(GOOGLE_CREDS_PATH, scopes=scopes)\n",
        "        client = gspread.authorize(creds)\n",
        "        try:\n",
        "             sheet = client.open(GOOGLE_SHEET_NAME).sheet1\n",
        "             return sheet, client\n",
        "        except gspread.exceptions.SpreadsheetNotFound:\n",
        "             st.error(f\"Google Sheet '{GOOGLE_SHEET_NAME}' not found. Ensure the name is exact and the sheet is shared with the service account email.\")\n",
        "             return None, None\n",
        "        except gspread.exceptions.APIError as api_e:\n",
        "             # Check if it's specifically a scope error even with both scopes\n",
        "             if 'insufficient authentication scopes' in str(api_e) or '403' in str(api_e):\n",
        "                 st.error(f\"❌ Google API Error (403): Still insufficient scopes reported. Double-check 'Google Sheets API' and 'Google Drive API' are ENABLED in Google Cloud Console for project '{creds.project_id}'.\")\n",
        "             else:\n",
        "                 st.error(f\"Google API Error accessing sheet '{GOOGLE_SHEET_NAME}': {api_e}. Check permissions and API enablement.\")\n",
        "             return None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to connect to Google Sheets: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Make sure the rest of Cell 3 remains the same\n",
        "\n",
        "def append_to_gsheet(sheet, data):\n",
        "    \"\"\"Appends extracted data as a new row in the Google Sheet.\"\"\"\n",
        "    try:\n",
        "        headers = [\n",
        "            'Extraction Date', 'Buyer Name', 'Buyer Address', 'Buyer Contact',\n",
        "            'Receipt Date', 'Store Name', 'Store Address', 'Total Amount',\n",
        "            'Items JSON'\n",
        "        ]\n",
        "        header_row = []\n",
        "        try:\n",
        "            header_row = sheet.row_values(1)\n",
        "        except gspread.exceptions.APIError as e:\n",
        "            st.warning(f\"Could not read header row: {e}. Assuming sheet is empty or permission issue.\")\n",
        "\n",
        "        if not header_row:\n",
        "             sheet.append_row(headers)\n",
        "             st.info(\"Added header row to empty Google Sheet.\")\n",
        "        elif header_row != headers:\n",
        "             st.warning(\"Sheet headers don't match expected headers. Appending based on defined order. Please check your Google Sheet columns.\")\n",
        "\n",
        "        row = [\n",
        "            datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            data.get('buyer_name', ''),\n",
        "            data.get('buyer_address', ''),\n",
        "            data.get('buyer_contact', ''),\n",
        "            data.get('receipt_date', ''),\n",
        "            data.get('store_name', ''),\n",
        "            data.get('store_address', ''),\n",
        "            data.get('total_amount', ''),\n",
        "            json.dumps(data.get('items', []), ensure_ascii=False)\n",
        "        ]\n",
        "        sheet.append_row(row)\n",
        "        return True\n",
        "    except gspread.exceptions.APIError as e:\n",
        "         st.error(f\"Google Sheets API error during append: {e}\")\n",
        "         return False\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to append data to Google Sheet: {e}\")\n",
        "        return False\n",
        "\n",
        "# --- Initialize Clients AFTER set_page_config ---\n",
        "# We wrap initialization in functions or use st.cache_resource for better practice\n",
        "\n",
        "@st.cache_resource # Cache the initialized OCR object\n",
        "def get_paddle_ocr():\n",
        "    try:\n",
        "        paddle_ocr_instance = PaddleOCR(use_angle_cls=True, lang='vi', use_gpu=False, show_log=False)\n",
        "        print(\"PaddleOCR initialized successfully for Vietnamese.\") # Use print for logs during init\n",
        "        return paddle_ocr_instance\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Could not initialize PaddleOCR: {e}. PaddleOCR option will be disabled.\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource # Cache the initialized LlamaParse object\n",
        "def get_llama_parser():\n",
        "    if LLAMAPARSE_API_KEY:\n",
        "        try:\n",
        "            parser_instance = LlamaParse(api_key=LLAMAPARSE_API_KEY, result_type=\"text\")\n",
        "            print(\"LlamaParse parser initialized successfully.\")\n",
        "            return parser_instance\n",
        "        except Exception as e:\n",
        "             st.warning(f\"Could not initialize LlamaParse: {e}. LlamaParse option disabled.\")\n",
        "             return None\n",
        "    else:\n",
        "        # No need for a warning here, handled later in the UI logic\n",
        "        # st.sidebar.warning(\"LlamaParse API Key not found. LlamaParse option disabled.\")\n",
        "        return None\n",
        "\n",
        "# Initialize clients using the cached functions\n",
        "paddle_ocr_instance = get_paddle_ocr()\n",
        "llama_parser_instance = get_llama_parser()\n",
        "\n",
        "# Configure OpenAI client (safe to do here)\n",
        "if OPENAI_API_KEY:\n",
        "    openai.api_key = OPENAI_API_KEY\n",
        "else:\n",
        "    # We'll show this warning in the UI instead of here\n",
        "    # st.warning(\"OpenAI API Key not found. LLM extraction will not work.\")\n",
        "    pass\n",
        "\n",
        "\n",
        "# --- Streamlit App UI ---\n",
        "\n",
        "st.title(\"🧾 Vietnamese Receipt OCR & Data Extraction\")\n",
        "st.info(\"Configured for Vietnamese language receipts (using Tesseract 'vie', PaddleOCR 'vi').\")\n",
        "\n",
        "# Initialize session state (safe to do after set_page_config)\n",
        "if 'ocr_text' not in st.session_state:\n",
        "    st.session_state.ocr_text = None\n",
        "if 'extracted_data' not in st.session_state:\n",
        "    st.session_state.extracted_data = None\n",
        "if 'file_processed' not in st.session_state:\n",
        "    st.session_state.file_processed = False\n",
        "if 'confirmed_data' not in st.session_state:\n",
        "    st.session_state.confirmed_data = None\n",
        "\n",
        "# --- Sidebar for Configuration ---\n",
        "with st.sidebar:\n",
        "    st.header(\"Configuration\")\n",
        "    uploaded_file = st.file_uploader(\"Upload Receipt (Image or PDF)\", type=[\"png\", \"jpg\", \"jpeg\", \"pdf\"])\n",
        "\n",
        "    # Determine available OCR options based on successful initialization\n",
        "    ocr_options = ['Tesseract (Local)'] # Tesseract is assumed available via apt-get\n",
        "    if paddle_ocr_instance:\n",
        "        ocr_options.insert(1, 'PaddleOCR (Local)')\n",
        "    else:\n",
        "        st.sidebar.warning(\"PaddleOCR option disabled (initialization failed).\")\n",
        "\n",
        "    if llama_parser_instance:\n",
        "        ocr_options.append('LlamaParse (API)')\n",
        "    elif LLAMAPARSE_API_KEY: # Key provided but init failed\n",
        "         st.sidebar.warning(\"LlamaParse option disabled (initialization failed).\")\n",
        "    else: # Key not provided\n",
        "         st.sidebar.info(\"LlamaParse option disabled (API key not configured).\")\n",
        "\n",
        "\n",
        "    if not ocr_options:\n",
        "         st.sidebar.error(\"No OCR engines available!\")\n",
        "         ocr_method = None\n",
        "    else:\n",
        "         # Set default index carefully, e.g., default to Paddle if available, else Tesseract\n",
        "         default_ocr_index = 0\n",
        "         if 'PaddleOCR (Local)' in ocr_options:\n",
        "              default_ocr_index = ocr_options.index('PaddleOCR (Local)')\n",
        "\n",
        "         ocr_method = st.radio(\n",
        "             \"Choose OCR Method:\",\n",
        "             options=ocr_options,\n",
        "             index=default_ocr_index,\n",
        "             help=\"Select the engine to extract text. Tesseract & Paddle configured for Vietnamese.\"\n",
        "         )\n",
        "\n",
        "    run_ocr = st.button(\"1. Run OCR\", disabled=(uploaded_file is None or ocr_method is None))\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    # Disable extraction button if no OCR text OR if OpenAI key is missing\n",
        "    openai_ready = bool(OPENAI_API_KEY)\n",
        "    run_extraction = st.button(\"2. Extract Data with LLM\",\n",
        "                               disabled=(st.session_state.ocr_text is None or not openai_ready))\n",
        "    if not openai_ready:\n",
        "         st.sidebar.error(\"OpenAI API Key not configured. LLM Extraction disabled.\")\n",
        "\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    # Google Sheet Config Info & Warnings\n",
        "    st.header(\"Google Sheet Export\")\n",
        "    st.info(f\"Sheet Name: {GOOGLE_SHEET_NAME or 'Not Set'}\")\n",
        "    st.info(f\"Credentials: {GOOGLE_CREDS_PATH or 'Not Set'}\")\n",
        "    creds_file_exists = os.path.exists(GOOGLE_CREDS_PATH) if GOOGLE_CREDS_PATH else False\n",
        "    gsheet_ready_for_export = GOOGLE_SHEET_NAME and GOOGLE_CREDS_PATH and creds_file_exists\n",
        "    if not gsheet_ready_for_export:\n",
        "         warning_msg = \"Export disabled: \"\n",
        "         if not GOOGLE_SHEET_NAME: warning_msg += \"Sheet Name missing. \"\n",
        "         if not GOOGLE_CREDS_PATH: warning_msg += \"Creds Path missing. \"\n",
        "         if GOOGLE_CREDS_PATH and not creds_file_exists: warning_msg += f\"Creds file not found. \"\n",
        "         st.warning(warning_msg)\n",
        "\n",
        "\n",
        "# --- Main Area ---\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.subheader(\"Uploaded File & OCR Text\")\n",
        "    if uploaded_file is not None:\n",
        "        file_bytes = uploaded_file.getvalue()\n",
        "        file_name = uploaded_file.name\n",
        "        file_type = uploaded_file.type\n",
        "\n",
        "        if file_type.startswith(\"image\"):\n",
        "            try:\n",
        "                st.image(file_bytes, caption=\"Uploaded Receipt Image\", use_column_width=True)\n",
        "            except Exception as img_e:\n",
        "                st.warning(f\"Could not display image preview: {img_e}\")\n",
        "        elif file_type == \"application/pdf\":\n",
        "            st.info(f\"Uploaded PDF: {file_name}.\")\n",
        "\n",
        "        if run_ocr and ocr_method:\n",
        "            st.session_state.ocr_text = None\n",
        "            st.session_state.extracted_data = None\n",
        "            st.session_state.confirmed_data = None\n",
        "            st.session_state.file_processed = True\n",
        "\n",
        "            with st.spinner(f\"Running {ocr_method} (Vietnamese)...\"):\n",
        "                if ocr_method == 'Tesseract (Local)':\n",
        "                    if file_type.startswith(\"image\"):\n",
        "                        st.session_state.ocr_text = process_image_tesseract(file_bytes)\n",
        "                    elif file_type == \"application/pdf\":\n",
        "                        st.session_state.ocr_text = process_pdf_tesseract(file_bytes)\n",
        "                elif ocr_method == 'PaddleOCR (Local)':\n",
        "                    # Pass the cached instance\n",
        "                    if file_type.startswith(\"image\"):\n",
        "                        st.session_state.ocr_text = process_image_paddle(file_bytes, paddle_ocr_instance)\n",
        "                    elif file_type == \"application/pdf\":\n",
        "                        st.session_state.ocr_text = process_pdf_paddle(file_bytes, paddle_ocr_instance)\n",
        "                elif ocr_method == 'LlamaParse (API)':\n",
        "                    # Pass the cached instance\n",
        "                     st.session_state.ocr_text = process_file_llamaparse(file_bytes, file_name, llama_parser_instance)\n",
        "\n",
        "            if st.session_state.ocr_text and st.session_state.ocr_text.strip():\n",
        "                st.success(\"OCR Completed!\")\n",
        "            else:\n",
        "                st.error(\"OCR failed or produced no text. Try a different OCR method or check the file.\")\n",
        "                st.session_state.ocr_text = None\n",
        "\n",
        "    if st.session_state.ocr_text:\n",
        "        with st.expander(\"Show OCR Text\", expanded=False):\n",
        "            st.text_area(\"OCR Output\", st.session_state.ocr_text, height=300, key=\"ocr_output_area\")\n",
        "    elif st.session_state.file_processed and not st.session_state.ocr_text:\n",
        "          st.warning(\"No OCR text was generated from the file.\")\n",
        "\n",
        "\n",
        "with col2:\n",
        "    st.subheader(\"Extracted Data & Confirmation\")\n",
        "\n",
        "    if run_extraction and st.session_state.ocr_text:\n",
        "        st.session_state.extracted_data = None\n",
        "        st.session_state.confirmed_data = None\n",
        "        with st.spinner(\"Calling LLM for data extraction (Vietnamese context)...\"):\n",
        "            st.session_state.extracted_data = extract_data_with_llm(st.session_state.ocr_text)\n",
        "\n",
        "        if st.session_state.extracted_data:\n",
        "             if \"raw_llm_output\" in st.session_state.extracted_data:\n",
        "                 st.warning(\"LLM did not return valid JSON. Cannot populate form.\")\n",
        "                 with st.expander(\"Show Raw LLM Output\"):\n",
        "                     st.code(st.session_state.extracted_data.get(\"raw_llm_output\", \"\"), language=None)\n",
        "                 st.session_state.extracted_data = {}\n",
        "             else:\n",
        "                 st.success(\"Data Extraction Attempted by LLM.\")\n",
        "                 st.write(\"Review and edit the extracted data below:\")\n",
        "        else:\n",
        "             st.error(\"LLM Data Extraction Failed.\")\n",
        "\n",
        "    # Check if data exists and is not the raw error dict\n",
        "    if st.session_state.extracted_data and \"raw_llm_output\" not in st.session_state.extracted_data:\n",
        "        with st.form(\"confirmation_form\"):\n",
        "            st.write(\"### Confirm Extracted Details\")\n",
        "            confirmed = {}\n",
        "\n",
        "            # --- Form Fields ---\n",
        "            c1, c2 = st.columns(2)\n",
        "            with c1:\n",
        "                confirmed['buyer_name'] = st.text_input(\"Buyer Name\", value=st.session_state.extracted_data.get('buyer_name', ''))\n",
        "                confirmed['buyer_address'] = st.text_area(\"Buyer Address\", value=st.session_state.extracted_data.get('buyer_address', ''), height=100)\n",
        "                confirmed['buyer_contact'] = st.text_input(\"Buyer Contact\", value=st.session_state.extracted_data.get('buyer_contact', ''))\n",
        "                # Date handling\n",
        "                default_date_str = st.session_state.extracted_data.get('receipt_date', '')\n",
        "                default_date = None\n",
        "                if default_date_str:\n",
        "                    try:\n",
        "                        default_date = datetime.datetime.strptime(default_date_str, '%Y-%m-%d').date()\n",
        "                    except ValueError:\n",
        "                        st.warning(f\"LLM date '{default_date_str}' not YYYY-MM-DD. Please verify.\")\n",
        "                        # Attempt common formats if needed, or leave blank for manual input\n",
        "                confirmed['receipt_date'] = st.date_input(\"Receipt Date\", value=default_date)\n",
        "\n",
        "            with c2:\n",
        "                confirmed['store_name'] = st.text_input(\"Store Name\", value=st.session_state.extracted_data.get('store_name', ''))\n",
        "                confirmed['store_address'] = st.text_area(\"Store Address\", value=st.session_state.extracted_data.get('store_address', ''), height=100)\n",
        "                # Total Amount handling\n",
        "                default_total_val = st.session_state.extracted_data.get('total_amount') # Keep as is from JSON initially\n",
        "                default_total_float = 0.0\n",
        "                if default_total_val is not None:\n",
        "                    try:\n",
        "                        default_total_float = float(default_total_val)\n",
        "                    except (ValueError, TypeError):\n",
        "                         st.warning(f\"Could not parse total amount: '{default_total_val}'. Defaulting to 0.0.\")\n",
        "                confirmed['total_amount'] = st.number_input(\"Total Amount (VND)\", value=default_total_float, format=\"%.0f\", step=1.0)\n",
        "\n",
        "\n",
        "            st.write(\"### Items Purchased\")\n",
        "            items_list = st.session_state.extracted_data.get('items', [])\n",
        "            if not isinstance(items_list, list):\n",
        "                 st.warning(f\"Items data is not a list (found {type(items_list)}). Displaying empty editor.\")\n",
        "                 items_list = []\n",
        "\n",
        "            try:\n",
        "                items_df = pd.DataFrame(items_list)\n",
        "            except Exception as df_err: # Broad exception for complex DataFrame init issues\n",
        "                st.error(f\"Could not create DataFrame from items list: {df_err}. Items might be malformed.\")\n",
        "                items_df = pd.DataFrame(columns=['description', 'quantity', 'price'])\n",
        "\n",
        "            required_cols = ['description', 'quantity', 'price']\n",
        "            for col in required_cols:\n",
        "                if col not in items_df.columns:\n",
        "                    items_df[col] = pd.NA # Use pandas NA for missing values\n",
        "\n",
        "            # Coerce to appropriate types, handling potential errors\n",
        "            items_df['description'] = items_df['description'].astype(str).fillna('')\n",
        "            items_df['quantity'] = pd.to_numeric(items_df['quantity'], errors='coerce').fillna(0).astype(int)\n",
        "            items_df['price'] = pd.to_numeric(items_df['price'], errors='coerce').fillna(0.0).astype(float)\n",
        "\n",
        "            # Ensure column order\n",
        "            items_df = items_df[required_cols]\n",
        "\n",
        "            edited_items_df = st.data_editor(\n",
        "                items_df,\n",
        "                num_rows=\"dynamic\",\n",
        "                column_config={\n",
        "                     \"quantity\": st.column_config.NumberColumn(\"Quantity\", format=\"%d\", step=1),\n",
        "                     \"price\": st.column_config.NumberColumn(\"Price (VND)\", format=\"%.0f\", step=1.0),\n",
        "                     \"description\": st.column_config.TextColumn(\"Description\", width=\"large\")\n",
        "                },\n",
        "                key=\"items_editor\",\n",
        "                use_container_width=True # Make editor wider\n",
        "             )\n",
        "            confirmed['items'] = edited_items_df.to_dict('records')\n",
        "\n",
        "            # Final data prep before saving\n",
        "            if confirmed.get('receipt_date'):\n",
        "                confirmed['receipt_date'] = confirmed['receipt_date'].strftime('%Y-%m-%d')\n",
        "            else:\n",
        "                 confirmed['receipt_date'] = ''\n",
        "\n",
        "            # Ensure total amount is stored appropriately (e.g., as number or string if GSheet prefers)\n",
        "            # Keeping it numeric as obtained from number_input is usually fine for gspread\n",
        "            # confirmed['total_amount'] = confirmed.get('total_amount', 0.0)\n",
        "\n",
        "\n",
        "            # --- Form Submission ---\n",
        "            submit_button = st.form_submit_button(\n",
        "                 \"Confirm & Save to Google Sheet\",\n",
        "                 disabled=not gsheet_ready_for_export # Use the flag calculated earlier\n",
        "             )\n",
        "\n",
        "            if submit_button:\n",
        "                st.session_state.confirmed_data = confirmed\n",
        "                st.write(\"Data confirmed. Attempting to save to Google Sheet...\")\n",
        "\n",
        "                sheet, client = connect_to_gsheet()\n",
        "                if sheet:\n",
        "                    with st.spinner(\"Appending data to Google Sheet...\"):\n",
        "                        success = append_to_gsheet(sheet, st.session_state.confirmed_data)\n",
        "                        if success:\n",
        "                            st.success(f\"Data successfully appended to Google Sheet '{GOOGLE_SHEET_NAME}'!\")\n",
        "                            # Consider clearing state or using st.rerun() here if desired\n",
        "                        else:\n",
        "                            st.error(\"Failed to save data to Google Sheet. Check previous error messages.\")\n",
        "                else:\n",
        "                    st.error(\"Cannot save data. Google Sheet connection failed. Check configuration and permissions.\")\n",
        "\n",
        "    elif run_extraction and not st.session_state.ocr_text:\n",
        "         st.warning(\"Please run OCR first to generate text for extraction.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# If you have an authtoken, uncomment and set it:\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "# Start Streamlit in background\n",
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.run(['streamlit', 'run', '--server.port', '8501', 'app.py'])\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# Set up ngrok tunnel\n",
        "public_url = ngrok.connect(addr='8501', proto='http')\n",
        "print(\"Your Streamlit app is available at:\", public_url)\n",
        "\n",
        "# Keep the Colab runtime alive\n",
        "import time\n",
        "while True:\n",
        "    time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "dDrccgRbj8oV",
        "outputId": "c5f2b91f-b0dc-4b5b-ccfa-98a2572af108"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Streamlit app is available at: NgrokTunnel: \"https://5bbb-34-48-54-26.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fd4d0c9c87ef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}