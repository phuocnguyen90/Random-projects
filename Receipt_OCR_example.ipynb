{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJNCi+qXHEFhPHQbXfc0VK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phuocnguyen90/Random-projects/blob/main/Receipt_OCR_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hướng dẫn nhanh sử dụng công cụ trích xuất hóa đơn\n",
        "\n",
        "File Google Colab này giúp bạn đọc thông tin từ ảnh hóa đơn và lưu vào Google Trang tính (Google Sheet).\n",
        "\n",
        "**Các bước thực hiện:**\n",
        "\n",
        "1.  **Chạy ô code #1 (Install dependencies):**\n",
        "    *   Tìm ô code đầu tiên có tiêu đề `Install dependencies`.\n",
        "    *   Nhấn nút ▶️ (Play) bên trái ô code đó để bắt đầu cài đặt.\n",
        "    *   **Chờ** cho ô code chạy xong (có thể mất vài phút, đến khi biểu tượng ngừng quay hoặc có dấu tick xanh).\n",
        "\n",
        "2.  **Chạy ô code #2 (Authenticate & Setup):**\n",
        "    *   Tìm ô code thứ hai (có tiêu đề `# Authenticate...`).\n",
        "    *   Nhấn nút ▶️ bên trái ô code.\n",
        "    *   **Nhập thông tin được yêu cầu** khi được hỏi:\n",
        "        *   `OpenRouter API Key`: Cần có để công cụ hiểu và trích xuất thông tin hóa đơn. Bạn có thể lấy key miễn phí tại [https://openrouter.ai/keys](https://openrouter.ai/keys).\n",
        "        *   `(Các API Key khác nếu có)`: Cần có Ngrok API (miễn phí tại https://ngrok.com/) để xuất đường link đến giao diện web. Có thể dùng LLamaparse API key (https://www.llamaindex.ai/llamaparse) để thực hiện OCR với độ chính xác cao hơn\n",
        "        *   `Tên Google Sheet`: Gõ **tên chính xác** của bảng tính Google Sheet bạn muốn dùng để lưu kết quả. Bảng tính này phải thuộc tài khoản Google bạn sẽ dùng ở bước sau.\n",
        "    *   Một **cửa sổ Google sẽ hiện ra**. Chọn tài khoản Google của bạn và nhấn **\"Cho phép\" (Allow)** để cấp quyền truy cập Google Sheet.\n",
        "    \n",
        "    *   Lưu ý bảo mật: Đối với đoạn code viết sẵn này **dữ liệu từ Google Sheet của bạn được bảo mật bởi chính Google. Tuy nhiên nội dung hóa đơn được gửi qua các dịch vụ AI khác (Gwen,Meta,Gemma,Deepseek bản free). Cần cân nhắc sử dụng**. Bạn có thể tùy chỉnh code để sử dụng ChatGPT API hoặc local LLM để đảm bảo bảo mật dữ liệu hơn.\n",
        "\n",
        "    *   Chờ ô code chạy xong và báo thành công (`✅ .env file created successfully`).\n",
        "\n",
        "3.  **Chạy ô code #3 (Write app.py):**\n",
        "    *   Nhấn nút ▶️ bên trái ô code thứ ba để tạo file ứng dụng. Bước này thường chạy rất nhanh.\n",
        "\n",
        "4.  **Chạy ô code #4 (Run Streamlit):**\n",
        "    *   Nhấn nút ▶️ bên trái ô code cuối cùng để khởi động ứng dụng web.\n",
        "    *   Chờ một lát, bạn sẽ thấy một dòng chữ như: `Your Streamlit app should be available at: https://....ngrok-free.app`\n",
        "\n",
        "5.  **Sử dụng Ứng dụng Web:**\n",
        "    *   **Nhấp vào đường link `.app`** vừa xuất hiện ở trên để mở ứng dụng trong tab mới.\n",
        "    *   Trong trang web đó:\n",
        "        *   **Tải lên (Upload)** file ảnh hóa đơn hoặc PDF từ máy tính của bạn ở cột bên trái.\n",
        "        *   Chọn phương thức OCR (thường để mặc định là Tesseract).\n",
        "        *   Nhấn nút **\"1. Run OCR\"**. Chờ kết quả OCR xuất hiện.\n",
        "        *   Nhấn nút **\"2. Extract Data with LLM\"**. Chờ thông tin được trích xuất ở cột bên phải.\n",
        "        *   **Xem lại và chỉnh sửa** thông tin (nếu cần) trong các ô ở cột bên phải.\n",
        "        *   Cuộn xuống dưới cùng cột phải và nhấn nút **\"Confirm & Save to Google Sheet\"** để lưu dữ liệu vào Google Sheet của bạn.\n",
        "\n",
        "**Lưu ý:** Nếu ứng dụng báo lỗi kết nối Google Sheet, hãy quay lại Colab, chạy lại **ô code #2** và **ô code #4**."
      ],
      "metadata": {
        "id": "UoppuYShJDNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Install dependencies (takes 1-2 mins)\n",
        "%%capture\n",
        "# Install system dependencies for Tesseract OCR and PDF processing\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install tesseract-ocr tesseract-ocr-vie poppler-utils -y\n",
        "\n",
        "# Install Python libraries\n",
        "!pip install streamlit pyngrok pytesseract pdf2image paddleocr paddlepaddle openai gspread google-auth google-auth-oauthlib python-dotenv llama-parse Pillow -q\n",
        "\n",
        "# Pillow is usually pre-installed, but explicit install ensures it's there.\n",
        "# Use paddlepaddle (CPU) for simplicity in Colab unless you have a GPU runtime and want GPU acceleration (paddlepaddle-gpu)\n",
        "# llama-parse is used here as an example API parser. Replace/add others if needed.\n",
        "# openai is used for the LLM extraction part. Replace/add others (e.g., anthropic, google-generativeai) if needed."
      ],
      "metadata": {
        "id": "_UZOTZtbv2VJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Authenticate Google User & Setup Environment (Explicit Credential Handling)\n",
        "# Cell 2: Use Colab's pop-up, explicitly get credentials, validate access\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "import gspread\n",
        "from google.colab import auth as colab_auth # Use Colab's auth mechanism\n",
        "import google.auth # <--- Import google.auth to explicitly get credentials\n",
        "from google.auth.exceptions import DefaultCredentialsError\n",
        "import openai\n",
        "import sys\n",
        "\n",
        "# Define scopes required by Sheets and Drive APIs\n",
        "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "\n",
        "print(\"--- User Input & Google Authentication ---\")\n",
        "print(\"Please enter API keys and the Google Sheet name.\")\n",
        "print(\"You will then be prompted via a pop-up to authenticate with Google.\")\n",
        "\n",
        "# --- 1. Get User Inputs ---\n",
        "openrouter_api_key = getpass('Enter your OpenRouter API Key: ')\n",
        "llamaparse_api_key = getpass('Enter your LlamaParse API Key (optional): ')\n",
        "ngrok_auth_token = getpass('Enter your NGROK Auth Token (optional): ')\n",
        "google_sheet_name = input('Enter the exact name of your Google Sheet: ')\n",
        "\n",
        "# --- 2. Perform Google Authentication via Colab ---\n",
        "print(\"\\n--- Authenticating Google User via Colab Pop-up ---\")\n",
        "colab_auth_ok = False\n",
        "try:\n",
        "    colab_auth.authenticate_user() # Trigger the pop-up\n",
        "    print(\"✅ Google User authenticated via Colab pop-up.\")\n",
        "    colab_auth_ok = True\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR: Colab authentication failed: {e}\")\n",
        "\n",
        "# --- 3. Explicitly Get Credentials & Validate Sheet Access ---\n",
        "gsheet_access_ok = False\n",
        "apis_enabled_ok = True\n",
        "gspread_client = None # Initialize client variable\n",
        "\n",
        "if colab_auth_ok and google_sheet_name:\n",
        "    print(f\"\\n--- Validating Access to Google Sheet: '{google_sheet_name}' ---\")\n",
        "    try:\n",
        "        # *** Explicitly get default credentials set by Colab auth ***\n",
        "        print(\"Attempting to fetch default credentials...\")\n",
        "        credentials, project_id = google.auth.default(scopes=SCOPES)\n",
        "        print(f\"✅ Successfully fetched default credentials (Project ID: {project_id}).\")\n",
        "\n",
        "        # *** Authorize gspread with the explicit credentials ***\n",
        "        print(\"Authorizing gspread client...\")\n",
        "        gc = gspread.authorize(credentials)\n",
        "        print(\"✅ gspread client authorized.\")\n",
        "        gspread_client = gc # Store client for potential reuse if needed\n",
        "\n",
        "        # *** Open the sheet ***\n",
        "        print(f\"Opening Google Sheet '{google_sheet_name}'...\")\n",
        "        spreadsheet = gc.open(google_sheet_name)\n",
        "        _ = spreadsheet.sheet1.title # Access a property to confirm\n",
        "        gsheet_access_ok = True\n",
        "        print(f\"✅ Successfully accessed Google Sheet '{google_sheet_name}'.\")\n",
        "\n",
        "    except DefaultCredentialsError as e:\n",
        "        # This error means google.auth.default() failed, even after Colab auth\n",
        "        print(f\"❌ ERROR: Could not get default credentials after Colab auth: {e}\")\n",
        "        print(\"   Try re-running this cell. If it persists, the Colab environment might have an issue.\")\n",
        "        colab_auth_ok = False # Mark as failed if we can't get creds\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        print(f\"❌ ERROR: Google Sheet '{google_sheet_name}' not found OR not shared with the authenticated Colab user.\")\n",
        "    except gspread.exceptions.APIError as e:\n",
        "        apis_enabled_ok = False\n",
        "        print(f\"❌ ERROR: Google API Error accessing sheet: {e}\")\n",
        "        if '403' in str(e) or 'PERMISSION_DENIED' in str(e):\n",
        "             print(\"   (Ensure Sheets & Drive APIs are enabled in Google Cloud and the user has permissions).\")\n",
        "    except Exception as e:\n",
        "        # Catch other potential errors during authorize or open\n",
        "        print(f\"❌ ERROR: Failed during gspread authorization or sheet opening: {type(e).__name__} - {e}\")\n",
        "\n",
        "elif not google_sheet_name:\n",
        "     print(\"ℹ️ INFO: Google Sheet Name not provided. Skipping sheet access validation.\")\n",
        "elif not colab_auth_ok:\n",
        "     print(\"ℹ️ INFO: Skipping sheet access validation due to failed Colab authentication.\")\n",
        "\n",
        "\n",
        "# --- 4. API Key Validation (OpenRouter & LlamaParse) ---\n",
        "# (This section remains the same as before)\n",
        "print(\"\\n--- API Key Validation ---\")\n",
        "openrouter_ok = False\n",
        "if openrouter_api_key:\n",
        "    print(\"Checking OpenRouter API Key presence...\")\n",
        "    openrouter_ok = True\n",
        "    print(\"✅ OpenRouter API Key provided (basic check).\")\n",
        "else:\n",
        "    print(\"ℹ️ INFO: OpenRouter API Key not provided. LLM extraction will be disabled.\")\n",
        "    openrouter_ok = True # Allow proceeding if key is not provided\n",
        "\n",
        "llamaparse_provided = bool(llamaparse_api_key)\n",
        "if llamaparse_provided: print(\"ℹ️ INFO: LlamaParse API Key provided (basic check only).\")\n",
        "else: print(\"ℹ️ INFO: LlamaParse API Key not provided. LlamaParse option will be disabled.\")\n",
        "\n",
        "\n",
        "# --- 5. Write .env File ---\n",
        "print(\"\\n--- Summary & .env Creation ---\")\n",
        "\n",
        "# Essentials: Colab Auth must succeed AND we must be able to get default creds,\n",
        "# AND ( (sheet name provided AND sheet access ok) OR sheet name not provided )\n",
        "# AND APIs must be enabled (or presumed enabled if access not attempted)\n",
        "essentials_ok = colab_auth_ok and \\\n",
        "                (gsheet_access_ok or not google_sheet_name) and \\\n",
        "                apis_enabled_ok\n",
        "\n",
        "if essentials_ok:\n",
        "    if google_sheet_name and not gsheet_access_ok: print(\"⚠️ WARNING: Google Sheet access validation failed. Streamlit app might fail.\")\n",
        "    elif not google_sheet_name: print(\"ℹ️ INFO: No Google Sheet name provided. Export disabled.\")\n",
        "    else: print(\"✅ Colab authentication and Sheet access validation successful.\")\n",
        "\n",
        "    if not openrouter_ok and openrouter_api_key: print(\"⚠️ WARNING: OpenRouter API Key validation skipped/failed.\")\n",
        "\n",
        "    try:\n",
        "        with open(\".env\", \"w\") as f:\n",
        "            if openrouter_api_key: f.write(f\"OPENROUTER_API_KEY={openrouter_api_key}\\n\")\n",
        "            if llamaparse_api_key: f.write(f\"LLAMAPARSE_API_KEY={llamaparse_api_key}\\n\")\n",
        "            if ngrok_auth_token: f.write(f\"NGROK_AUTH_TOKEN={ngrok_auth_token}\\n\")\n",
        "            if google_sheet_name: f.write(f\"GOOGLE_SHEET_NAME={google_sheet_name}\\n\")\n",
        "\n",
        "        print(\"✅ .env file created successfully.\")\n",
        "        print(\"You can now proceed to run Cell 3 (Write app.py) and Cell 4 (Run Streamlit).\")\n",
        "        print(\"NOTE: If the Streamlit app later shows Google connection errors,\")\n",
        "        print(\"      you may need to re-run this cell to refresh Colab authentication.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERROR: Failed to write .env file: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ ERROR: Essential validation failed. Cannot write .env file.\")\n",
        "    print(\"Please review the errors above and rerun this cell.\")\n",
        "    if not colab_auth_ok: print(\"   - Issue: Google authentication via Colab failed OR could not fetch default credentials after auth.\")\n",
        "    # The error 'Sheet not found...' now implies colab_auth_ok was true, but access failed later\n",
        "    if colab_auth_ok and google_sheet_name and not gsheet_access_ok:\n",
        "        # Distinguish between API not enabled and sheet not found/shared\n",
        "        if not apis_enabled_ok:\n",
        "            print(\"   - Issue: Google Sheets/Drive API likely not enabled or permission issue detected.\")\n",
        "        else:\n",
        "            print(\"   - Issue: Google Sheet not found or not shared correctly with the authenticated user.\")\n",
        "    # Check OpenRouter only if it was the reason for failure (less likely)\n",
        "    # if not openrouter_ok: print(\"   - Issue: OpenRouter validation failed (if applicable).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "uVdu9kdt42NY",
        "outputId": "761c0571-d3f0-4e67-ed29-2f36c230412b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- User Input & Google Authentication ---\n",
            "Please enter API keys and the Google Sheet name.\n",
            "You will then be prompted via a pop-up to authenticate with Google.\n",
            "Enter your OpenRouter API Key: ··········\n",
            "Enter your LlamaParse API Key (optional): ··········\n",
            "Enter your NGROK Auth Token (optional): ··········\n",
            "Enter the exact name of your Google Sheet: receipt\n",
            "\n",
            "--- Authenticating Google User via Colab Pop-up ---\n",
            "✅ Google User authenticated via Colab pop-up.\n",
            "\n",
            "--- Validating Access to Google Sheet: 'receipt' ---\n",
            "Attempting to fetch default credentials...\n",
            "✅ Successfully fetched default credentials (Project ID: ).\n",
            "Authorizing gspread client...\n",
            "✅ gspread client authorized.\n",
            "Opening Google Sheet 'receipt'...\n",
            "✅ Successfully accessed Google Sheet 'receipt'.\n",
            "\n",
            "--- API Key Validation ---\n",
            "Checking OpenRouter API Key presence...\n",
            "✅ OpenRouter API Key provided (basic check).\n",
            "ℹ️ INFO: LlamaParse API Key not provided. LlamaParse option will be disabled.\n",
            "\n",
            "--- Summary & .env Creation ---\n",
            "✅ Colab authentication and Sheet access validation successful.\n",
            "✅ .env file created successfully.\n",
            "You can now proceed to run Cell 3 (Write app.py) and Cell 4 (Run Streamlit).\n",
            "NOTE: If the Streamlit app later shows Google connection errors,\n",
            "      you may need to re-run this cell to refresh Colab authentication.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ASc1NpEiwY4",
        "outputId": "5bb467ea-6ac0-435e-a071-aa5dab64191d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "# @title 3. Write app.py\n",
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_bytes\n",
        "from paddleocr import PaddleOCR\n",
        "import openai\n",
        "import gspread\n",
        "import google.auth # <--- Import google.auth\n",
        "from google.auth.exceptions import DefaultCredentialsError\n",
        "from llama_parse import LlamaParse\n",
        "from dotenv import load_dotenv\n",
        "import io\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import asyncio\n",
        "\n",
        "\n",
        "\n",
        "# --- Page Config MUST BE THE FIRST STREAMLIT COMMAND ---\n",
        "st.set_page_config(layout=\"wide\")\n",
        "\n",
        "# --- Configuration & Initialization ---\n",
        "load_dotenv()\n",
        "\n",
        "# --- MODIFIED: Load OpenRouter Key ---\n",
        "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "# --- End Modification ---\n",
        "LLAMAPARSE_API_KEY = os.getenv(\"LLAMAPARSE_API_KEY\")\n",
        "GOOGLE_SHEET_NAME = os.getenv(\"GOOGLE_SHEET_NAME\")\n",
        "NGROK_AUTH_TOKEN = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "# --- Add OpenRouter Configuration ---\n",
        "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "FREE_ROUTER_MODELS = [\n",
        "    \"qwen/qwen2.5-vl-32b-instruct:free\", # Most likely to support JSON mode from this list\n",
        "    \"meta-llama/llama-4-scout:free\",\n",
        "    \"google/gemma-3-12b-it:free\",\n",
        "    \"deepseek/deepseek-v3-base:free\",\n",
        "]\n",
        "\n",
        "# Define the model to use on OpenRouter (must match their naming)\n",
        "# Examples: \"openai/gpt-4o\", \"google/gemini-pro-1.5\", \"anthropic/claude-3-haiku\"\n",
        "# Let's default to gpt-4o via OpenRouter\n",
        "DEFAULT_OPENROUTER_MODEL = os.getenv(\"OPENROUTER_MODEL\", \"meta-llama/llama-4-scout:free\")\n",
        "\n",
        "# Define scopes needed by gspread\n",
        "GSPREAD_SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "\n",
        "\n",
        "# --- Initialize OpenRouter Client (using openai library structure) ---\n",
        "openrouter_client = None\n",
        "if OPENROUTER_API_KEY:\n",
        "    try:\n",
        "\n",
        "        openrouter_client = openai.OpenAI(\n",
        "            base_url=OPENROUTER_BASE_URL,\n",
        "            api_key=OPENROUTER_API_KEY,\n",
        "            # default_headers=headers # Uncomment to add headers\n",
        "        )\n",
        "        print(\"OpenRouter client initialized.\") # Log for server console\n",
        "    except Exception as e:\n",
        "\n",
        "        st.error(f\"Failed to initialize OpenRouter client: {e}\", icon=\"❌\")\n",
        "# --- End Client Initialization ---\n",
        "\n",
        "\n",
        "# --- Helper Functions (OCR, PDF, LlamaParse remain the same) ---\n",
        "\n",
        "def process_image_tesseract(image_bytes):\n",
        "    \"\"\"Performs OCR on image bytes using Tesseract for Vietnamese.\"\"\"\n",
        "    try:\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        text = pytesseract.image_to_string(image, lang='vie')\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Tesseract OCR failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_pdf_tesseract(pdf_bytes):\n",
        "    \"\"\"Converts PDF to images and performs OCR using Tesseract for Vietnamese.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        images = convert_from_bytes(pdf_bytes)\n",
        "        for i, image in enumerate(images):\n",
        "            # st.write(f\"Processing PDF page {i+1} with Tesseract (Vietnamese)...\") # Reduce noise\n",
        "            text += pytesseract.image_to_string(image, lang='vie') + \"\\n\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Tesseract PDF processing failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_image_paddle(image_bytes, paddle_ocr_instance):\n",
        "    \"\"\"Performs OCR on image bytes using PaddleOCR (already configured for Vietnamese).\"\"\"\n",
        "    if paddle_ocr_instance is None:\n",
        "        st.error(\"PaddleOCR is not initialized.\")\n",
        "        return None\n",
        "    try:\n",
        "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "        image_np = np.array(image)\n",
        "        result = paddle_ocr_instance.ocr(image_np, cls=True)\n",
        "        text = \"\"\n",
        "        if result and result[0]:\n",
        "            for line in result[0]:\n",
        "                text += line[1][0] + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"PaddleOCR failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_pdf_paddle(pdf_bytes, paddle_ocr_instance):\n",
        "    \"\"\"Converts PDF to images and performs OCR using PaddleOCR (already configured for Vietnamese).\"\"\"\n",
        "    if paddle_ocr_instance is None:\n",
        "        st.error(\"PaddleOCR is not initialized.\")\n",
        "        return None\n",
        "    text = \"\"\n",
        "    try:\n",
        "        images = convert_from_bytes(pdf_bytes)\n",
        "        for i, image in enumerate(images):\n",
        "            # st.write(f\"Processing PDF page {i+1} with PaddleOCR (Vietnamese)...\") # Reduce noise\n",
        "            image_np = np.array(image.convert(\"RGB\"))\n",
        "            result = paddle_ocr_instance.ocr(image_np, cls=True)\n",
        "            if result and result[0]:\n",
        "                for line in result[0]:\n",
        "                    text += line[1][0] + \"\\n\"\n",
        "            text += \"\\n\\n\" # Add separator between pages\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"PaddleOCR PDF processing failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_file_llamaparse(file_bytes, filename, parser_instance):\n",
        "    \"\"\"Uses LlamaParse API to extract text from image or PDF.\"\"\"\n",
        "    if parser_instance is None:\n",
        "        # Error/info message handled in sidebar based on key presence/init status\n",
        "        # st.error(\"LlamaParse parser not initialized.\")\n",
        "        return None\n",
        "    temp_filepath = None\n",
        "    try:\n",
        "        # Ensure temp file has extension if needed by parser\n",
        "        _, extension = os.path.splitext(filename)\n",
        "        temp_filepath = f\"./temp_llamaparse{extension}\"\n",
        "        with open(temp_filepath, \"wb\") as f:\n",
        "            f.write(file_bytes)\n",
        "\n",
        "        # Handle asyncio event loop for Streamlit\n",
        "        try:\n",
        "            loop = asyncio.get_event_loop_policy().get_event_loop()\n",
        "            # Use loop.is_running() check if needed, but run_until_complete usually handles it\n",
        "        except RuntimeError:\n",
        "            loop = asyncio.new_event_loop()\n",
        "            asyncio.set_event_loop(loop)\n",
        "\n",
        "        # Await the async call correctly\n",
        "        documents = loop.run_until_complete(parser_instance.aload_data(temp_filepath))\n",
        "\n",
        "        if documents:\n",
        "            # Combine text from potentially multiple documents LlamaParse might return\n",
        "            full_text = \"\\n\\n\".join([doc.text for doc in documents])\n",
        "            return full_text\n",
        "        else:\n",
        "             st.warning(\"LlamaParse returned no documents.\", icon=\"⚠️\")\n",
        "             return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"LlamaParse API call failed: {e}\", icon=\"❌\")\n",
        "        return None\n",
        "    finally:\n",
        "        if temp_filepath and os.path.exists(temp_filepath):\n",
        "            try:\n",
        "                os.remove(temp_filepath)\n",
        "            except OSError as e:\n",
        "                st.warning(f\"Could not remove temporary file {temp_filepath}: {e}\", icon=\"⚠️\")\n",
        "\n",
        "# --- MODIFIED: extract_data_with_llm function (Model Routing Logic) ---\n",
        "def extract_data_with_llm(text):\n",
        "    \"\"\"Uses OpenRouter with model routing to extract structured data.\"\"\"\n",
        "    global openrouter_client\n",
        "    if not openrouter_client:\n",
        "        st.error(\"OpenRouter client not initialized. Check API Key.\", icon=\"❗\")\n",
        "        return None\n",
        "    if not text or not text.strip():\n",
        "        st.warning(\"No text provided for extraction.\", icon=\"⚠️\")\n",
        "        return None\n",
        "\n",
        "    # The prompt remains the same\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert assistant specialized in extracting information from Vietnamese receipts.\n",
        "    The following text was extracted from a receipt, likely in Vietnamese.\n",
        "    Extract the key information and format the output as a single JSON object.\n",
        "    Use the exact English keys provided below. If a value is not found, use null or an empty string \"\".\n",
        "\n",
        "    Keys to extract:\n",
        "    - 'buyer_name': Name of the customer/buyer (Tên khách hàng).\n",
        "    - 'buyer_address': Address of the customer/buyer (Địa chỉ khách hàng).\n",
        "    - 'buyer_contact': Phone number or email of the customer/buyer (SĐT/Email khách hàng).\n",
        "    - 'receipt_date': Date the receipt was issued (Ngày hóa đơn). Format this as YYYY-MM-DD. If the date is like DD/MM/YYYY or DD-MM-YYYY, convert it.\n",
        "    - 'store_name': Name of the store/vendor (Tên cửa hàng / Đơn vị bán).\n",
        "    - 'store_address': Address of the store/vendor (Địa chỉ cửa hàng).\n",
        "    - 'total_amount': The final total amount paid (Tổng cộng / Tổng thanh toán). Provide only the numerical value, removing currency symbols like 'đ' or 'VND' and thousand separators like '.' or ','.\n",
        "    - 'items': A list of items purchased. Each item MUST be an object with 'description' (Tên hàng / Mô tả), 'quantity' (Số lượng - SL), and 'price' (Đơn giá or Thành tiền). Extract numerical values for quantity and price.\n",
        "\n",
        "    Important Notes:\n",
        "    - The text is in Vietnamese. Pay attention to Vietnamese names, addresses, and date formats (DD/MM/YYYY).\n",
        "    - For 'total_amount', 'quantity', and 'price', extract only numbers. Handle separators (like '.' for thousands in VND) correctly. For example, '50.000 đ' should become 50000.\n",
        "    - Output only the JSON object, nothing else before or after it.\n",
        "\n",
        "    Receipt Text (Vietnamese):\n",
        "    ---\n",
        "    {text}\n",
        "    ---\n",
        "\n",
        "    JSON Output:\n",
        "    \"\"\"\n",
        "\n",
        "    extracted_data = None\n",
        "    last_error = None\n",
        "    last_error_model = None\n",
        "    successful_model = None\n",
        "\n",
        "    # Optionally shuffle the list each time to distribute load\n",
        "    # current_model_list = random.sample(FREE_ROUTER_MODELS, len(FREE_ROUTER_MODELS))\n",
        "    current_model_list = FREE_ROUTER_MODELS # Or use the fixed order\n",
        "\n",
        "    st.info(f\"Attempting extraction using free models: {', '.join(current_model_list)}\")\n",
        "\n",
        "    for model_name in current_model_list:\n",
        "        st.write(f\"Trying model: `{model_name}`...\") # Give feedback on attempts\n",
        "        content = None # Reset content for each model attempt\n",
        "        try:\n",
        "            response = openrouter_client.chat.completions.create(\n",
        "                model=model_name, # Use the current model from the list\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert receipt data extraction assistant specializing in Vietnamese documents.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                response_format={\"type\": \"json_object\"}, # Attempt JSON mode\n",
        "                temperature=0.1,\n",
        "                # Add a timeout? e.g., timeout=30.0\n",
        "            )\n",
        "            content = response.choices[0].message.content\n",
        "\n",
        "            # Try parsing the JSON\n",
        "            try:\n",
        "                extracted_data = json.loads(content)\n",
        "                # Basic validation: Check if it's a dictionary\n",
        "                if isinstance(extracted_data, dict):\n",
        "                    st.success(f\"✅ Successfully extracted data using `{model_name}`!\")\n",
        "                    successful_model = model_name\n",
        "                    break # Exit loop on first successful extraction and parse\n",
        "                else:\n",
        "                    st.warning(f\"⚠️ Model `{model_name}` returned valid JSON, but it wasn't a dictionary. Trying next.\", icon=\"⚠️\")\n",
        "                    last_error = f\"Returned non-dict JSON: {content[:100]}...\"\n",
        "                    last_error_model = model_name\n",
        "                    extracted_data = None # Reset data as it wasn't the expected type\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                st.warning(f\"⚠️ Model `{model_name}` returned invalid JSON. Trying next.\", icon=\"⚠️\")\n",
        "                # Optionally show the invalid JSON\n",
        "                # with st.expander(f\"Invalid JSON from {model_name}\"):\n",
        "                #    st.code(content, language=None)\n",
        "                last_error = f\"Invalid JSON: {content[:100]}...\"\n",
        "                last_error_model = model_name\n",
        "                # Keep extracted_data as None and continue loop\n",
        "\n",
        "        except openai.AuthenticationError as e:\n",
        "             st.error(\"OpenRouter Authentication Error: Invalid API Key?\", icon=\"❗\")\n",
        "             return None # Auth errors are fatal, no point trying other models\n",
        "        except openai.RateLimitError as e:\n",
        "             st.warning(f\"⏳ Rate limit hit for `{model_name}`. Trying next...\", icon=\"⏳\")\n",
        "             last_error = e\n",
        "             last_error_model = model_name\n",
        "             continue # Try the next model\n",
        "        except openai.APITimeoutError as e:\n",
        "             st.warning(f\"⏳ Timeout connecting to `{model_name}`. Trying next...\", icon=\"⏳\")\n",
        "             last_error = e\n",
        "             last_error_model = model_name\n",
        "             continue\n",
        "        except openai.APIError as e: # Catch other OpenRouter/model-specific API errors\n",
        "            st.warning(f\"❌ API Error with `{model_name}` (Code: {e.status_code}): {e.message}. Trying next...\", icon=\"❌\")\n",
        "            last_error = e\n",
        "            last_error_model = model_name\n",
        "            continue # Try the next model\n",
        "        except Exception as e:\n",
        "            st.warning(f\"⚠️ Unexpected error with `{model_name}`: {type(e).__name__}. Trying next...\", icon=\"⚠️\")\n",
        "            last_error = e\n",
        "            last_error_model = model_name\n",
        "            continue # Try the next model\n",
        "\n",
        "    # After the loop completes\n",
        "    if successful_model:\n",
        "        return extracted_data # Return the successfully parsed data\n",
        "    else:\n",
        "        st.error(\"❌ All attempted free models failed to extract valid data.\", icon=\"❌\")\n",
        "        if last_error:\n",
        "            st.caption(f\"Last error encountered (with `{last_error_model}`): {last_error}\")\n",
        "        return None # Indicate failure\n",
        "\n",
        "# --- Google Sheet Functions (get_gspread_client, connect_to_gsheet, append_to_gsheet remain the same) ---\n",
        "@st.cache_resource(ttl=600)\n",
        "def get_gspread_client():\n",
        "    \"\"\"Attempts to get an authorized gspread client using explicit default credentials.\"\"\"\n",
        "    try:\n",
        "        # Explicitly get default credentials set by Colab auth\n",
        "        credentials, project = google.auth.default(scopes=GSPREAD_SCOPES)\n",
        "        # *** Authorize gspread with the explicit credentials ***\n",
        "        client = gspread.authorize(credentials) # <--- THE CORRECTION\n",
        "        st.success(\"Successfully obtained Google API client via Colab credentials.\", icon=\"✅\")\n",
        "        return client\n",
        "    except DefaultCredentialsError:\n",
        "        st.error(\"❌ Google Credentials not found by application.\", icon=\"🚨\")\n",
        "        st.warning(\"💡 Please run the 'Authenticate Google User' cell in Colab and RESTART this Streamlit app.\", icon=\"💡\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Failed to initialize Google client: {type(e).__name__} - {e}\", icon=\"🚨\")\n",
        "        return None\n",
        "\n",
        "def connect_to_gsheet():\n",
        "    \"\"\"Connects to the specified Google Sheet.\"\"\"\n",
        "    if not GOOGLE_SHEET_NAME: st.warning(\"Sheet Name missing.\", icon=\"⚠️\"); return None, None\n",
        "    client = get_gspread_client() # Uses the corrected function\n",
        "    if client:\n",
        "        try: spreadsheet = client.open(GOOGLE_SHEET_NAME); sheet = spreadsheet.sheet1; return sheet, client\n",
        "        except gspread.exceptions.SpreadsheetNotFound: st.error(f\"❌ Sheet '{GOOGLE_SHEET_NAME}' not found/shared.\", icon=\"🚨\"); return None, None\n",
        "        except gspread.exceptions.APIError as e: st.error(f\"❌ Google API Error: {e}.\", icon=\"🚨\"); return None, None\n",
        "        except Exception as e: st.error(f\"❌ Failed to open Sheet: {e}\", icon=\"🚨\"); return None, None\n",
        "    else: return None, None # Error handled in get_gspread_client\n",
        "\n",
        "\n",
        "def append_to_gsheet(sheet, data):\n",
        "    \"\"\"Appends extracted data as a new row in the Google Sheet.\"\"\"\n",
        "    # ... (This function's logic remains exactly the same) ...\n",
        "    try:\n",
        "        headers = [\n",
        "            'Extraction Date', 'Buyer Name', 'Buyer Address', 'Buyer Contact',\n",
        "            'Receipt Date', 'Store Name', 'Store Address', 'Total Amount',\n",
        "            'Items JSON'\n",
        "        ]\n",
        "        header_row = []\n",
        "        try:\n",
        "            header_row = sheet.row_values(1)\n",
        "        except gspread.exceptions.APIError as e:\n",
        "             if 'PERMISSION_DENIED' in str(e) or '403' in str(e):\n",
        "                 st.warning(f\"Could not read header row (Permission Denied: {e}). Assuming headers exist or sheet is empty. Attempting to append.\", icon=\"⚠️\")\n",
        "             else:\n",
        "                st.warning(f\"Could not read header row ({e}). Assuming sheet is empty.\", icon=\"⚠️\")\n",
        "                header_row = []\n",
        "\n",
        "        if not header_row:\n",
        "             try:\n",
        "                 sheet.append_row(headers, value_input_option='USER_ENTERED')\n",
        "                 st.info(\"Added header row to Google Sheet.\", icon=\"ℹ️\")\n",
        "             except gspread.exceptions.APIError as append_e:\n",
        "                 st.error(f\"Failed to add header row: {append_e}. Check sheet write permissions.\", icon=\"❌\")\n",
        "                 return False\n",
        "        elif header_row != headers:\n",
        "             st.warning(\"Sheet headers don't match expected headers. Appending based on defined order. Please check your Google Sheet columns.\", icon=\"⚠️\")\n",
        "\n",
        "        row_to_append = [\n",
        "            datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            data.get('buyer_name', ''),\n",
        "            data.get('buyer_address', ''),\n",
        "            data.get('buyer_contact', ''),\n",
        "            data.get('receipt_date', ''),\n",
        "            data.get('store_name', ''),\n",
        "            data.get('store_address', ''),\n",
        "            data.get('total_amount', ''),\n",
        "            json.dumps(data.get('items', []), ensure_ascii=False)\n",
        "        ]\n",
        "        sheet.append_row(row_to_append, value_input_option='USER_ENTERED')\n",
        "        return True\n",
        "    except gspread.exceptions.APIError as e:\n",
        "         st.error(f\"Google Sheets API error during append: {e}\", icon=\"❌\")\n",
        "         return False\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to append data to Google Sheet: {e}\", icon=\"❌\")\n",
        "        return False\n",
        "\n",
        "# --- Initialize OCR/Parser Clients (Paddle, LlamaParse remain the same) ---\n",
        "@st.cache_resource\n",
        "def get_paddle_ocr():\n",
        "    try:\n",
        "        paddle_ocr_instance = PaddleOCR(use_angle_cls=True, lang='vi', use_gpu=False, show_log=False)\n",
        "        print(\"PaddleOCR initialized successfully for Vietnamese.\")\n",
        "        return paddle_ocr_instance\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Could not initialize PaddleOCR: {e}. PaddleOCR option will be disabled.\", icon=\"⚠️\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource\n",
        "def get_llama_parser():\n",
        "    if LLAMAPARSE_API_KEY:\n",
        "        try:\n",
        "            parser_instance = LlamaParse(api_key=LLAMAPARSE_API_KEY, result_type=\"text\")\n",
        "            print(\"LlamaParse parser initialized successfully.\")\n",
        "            return parser_instance\n",
        "        except Exception as e:\n",
        "             st.warning(f\"Could not initialize LlamaParse: {e}. LlamaParse option disabled.\", icon=\"⚠️\")\n",
        "             return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "paddle_ocr_instance = get_paddle_ocr()\n",
        "llama_parser_instance = get_llama_parser()\n",
        "\n",
        "# --- Streamlit App UI ---\n",
        "st.title(\"🧾 Vietnamese Receipt OCR & Data Extraction (OpenRouter LLM)\") # Updated Title\n",
        "st.info(f\"Uses Colab Auth for GSheets & OpenRouter ({DEFAULT_OPENROUTER_MODEL}) for LLM extraction.\")\n",
        "\n",
        "# Initialize session state (remains the same)\n",
        "# ... (ocr_text, extracted_data, etc.) ...\n",
        "if 'ocr_text' not in st.session_state: st.session_state.ocr_text = None\n",
        "if 'extracted_data' not in st.session_state: st.session_state.extracted_data = None\n",
        "if 'file_processed' not in st.session_state: st.session_state.file_processed = False\n",
        "if 'confirmed_data' not in st.session_state: st.session_state.confirmed_data = None\n",
        "\n",
        "\n",
        "# --- Sidebar for Configuration ---\n",
        "with st.sidebar:\n",
        "    st.header(\"Configuration\")\n",
        "    uploaded_file = st.file_uploader(\"Upload Receipt (Image or PDF)\", type=[\"png\", \"jpg\", \"jpeg\", \"pdf\"])\n",
        "\n",
        "    # (OCR Method Selection - Remains the same)\n",
        "    ocr_options = ['Tesseract (Local)']\n",
        "    if paddle_ocr_instance: ocr_options.insert(0, 'PaddleOCR (Local)')\n",
        "    else: st.warning(\"PaddleOCR option disabled (initialization failed).\", icon=\"⚠️\")\n",
        "    if llama_parser_instance: ocr_options.append('LlamaParse (API)')\n",
        "    elif LLAMAPARSE_API_KEY: st.warning(\"LlamaParse option disabled (initialization failed).\", icon=\"⚠️\")\n",
        "\n",
        "\n",
        "    default_ocr_index = 0 # Default to 0 (Tesseract)\n",
        "    tesseract_label = 'Tesseract (Local)'\n",
        "    if tesseract_label in ocr_options:\n",
        "        try:\n",
        "            default_ocr_index = ocr_options.index(tesseract_label)\n",
        "        except ValueError:\n",
        "            pass # Should not happen as we always add it, but safer\n",
        "\n",
        "\n",
        "    if not ocr_options:\n",
        "         st.error(\"No OCR engines available!\", icon=\"❌\")\n",
        "         ocr_method = None\n",
        "    else:\n",
        "         default_ocr_index = 0\n",
        "         ocr_method = st.radio(\"Choose OCR Method:\", options=ocr_options, index=default_ocr_index)\n",
        "\n",
        "    run_ocr = st.button(\"1. Run OCR\", disabled=(uploaded_file is None or ocr_method is None), use_container_width=True)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    # --- MODIFIED: LLM Extraction Button Check ---\n",
        "    openrouter_ready = bool(openrouter_client) # Check if client initialized successfully\n",
        "    extract_button_disabled = (not st.session_state.get('ocr_text') or not openrouter_ready)\n",
        "    run_extraction = st.button(\"2. Extract Data with LLM\",\n",
        "                               disabled=extract_button_disabled,\n",
        "                               use_container_width=True)\n",
        "    if not openrouter_ready:\n",
        "         st.error(\"OpenRouter API Key missing or invalid. LLM Extraction disabled.\", icon=\"❗\")\n",
        "    # --- End Modification ---\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    # (Google Sheet Config Info - Remains the same)\n",
        "    st.header(\"Google Sheet Export\")\n",
        "    gsheet_ready_for_export = False # Default to false\n",
        "    if GOOGLE_SHEET_NAME:\n",
        "        st.info(f\"Target Sheet: '{GOOGLE_SHEET_NAME}'\", icon=\"📄\")\n",
        "        client_check = get_gspread_client() # Check connection status\n",
        "        gsheet_ready_for_export = client_check is not None\n",
        "\n",
        "    else:\n",
        "        st.info(\"No Google Sheet name configured.\", icon=\"ℹ️\")\n",
        "\n",
        "\n",
        "# --- Main Area ---\n",
        "# (OCR Execution logic remains the same)\n",
        "# (Extracted Data & Confirmation Form logic remains the same, but relies on the modified extract_data_with_llm)\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    # Display Uploaded File & Run OCR Logic\n",
        "    st.subheader(\"Uploaded File & OCR Text\")\n",
        "    if uploaded_file is not None:\n",
        "        file_bytes = uploaded_file.getvalue()\n",
        "        file_name = uploaded_file.name\n",
        "        file_type = uploaded_file.type\n",
        "\n",
        "        if file_type.startswith(\"image\"):\n",
        "            try:\n",
        "                st.image(file_bytes, caption=\"Uploaded Receipt Image\", use_column_width=True)\n",
        "            except Exception as img_e:\n",
        "                st.warning(f\"Could not display image preview: {img_e}\", icon=\"⚠️\")\n",
        "        elif file_type == \"application/pdf\":\n",
        "            st.info(f\"Uploaded PDF: {file_name}.\", icon=\"📄\")\n",
        "\n",
        "        if run_ocr and ocr_method:\n",
        "            # Reset states before running\n",
        "            st.session_state.ocr_text = None\n",
        "            st.session_state.extracted_data = None\n",
        "            st.session_state.confirmed_data = None\n",
        "            st.session_state.file_processed = True # Mark that processing was attempted\n",
        "            ocr_output = None # Temp variable\n",
        "\n",
        "            with st.spinner(f\"Running {ocr_method}...\"):\n",
        "                if ocr_method == 'Tesseract (Local)':\n",
        "                    if file_type.startswith(\"image\"): ocr_output = process_image_tesseract(file_bytes)\n",
        "                    elif file_type == \"application/pdf\": ocr_output = process_pdf_tesseract(file_bytes)\n",
        "                elif ocr_method == 'PaddleOCR (Local)':\n",
        "                    if file_type.startswith(\"image\"): ocr_output = process_image_paddle(file_bytes, paddle_ocr_instance)\n",
        "                    elif file_type == \"application/pdf\": ocr_output = process_pdf_paddle(file_bytes, paddle_ocr_instance)\n",
        "                elif ocr_method == 'LlamaParse (API)':\n",
        "                     ocr_output = process_file_llamaparse(file_bytes, file_name, llama_parser_instance)\n",
        "\n",
        "            st.session_state.ocr_text = ocr_output # Assign result to session state\n",
        "\n",
        "            if st.session_state.ocr_text and st.session_state.ocr_text.strip():\n",
        "                st.success(\"OCR Completed!\", icon=\"✅\")\n",
        "                # --- Force rerun to update button state ---\n",
        "                st.rerun()\n",
        "                # --- End force rerun ---\n",
        "            else:\n",
        "                st.error(\"OCR failed or produced no text.\", icon=\"❌\")\n",
        "                # No rerun needed if OCR failed, button should remain disabled\n",
        "        # --- End Run OCR Logic Modification ---\n",
        "\n",
        "    if st.session_state.ocr_text:\n",
        "        st.text_area(\"OCR Output\", st.session_state.ocr_text, height=350, key=\"ocr_output_area\")\n",
        "    elif st.session_state.file_processed and not st.session_state.ocr_text:\n",
        "          st.warning(\"No OCR text was generated from the file.\", icon=\"⚠️\")\n",
        "\n",
        "with col2:\n",
        "    st.subheader(\"Extracted Data & Confirmation\")\n",
        "\n",
        "    if run_extraction and st.session_state.ocr_text:\n",
        "        st.session_state.extracted_data = None\n",
        "        st.session_state.confirmed_data = None\n",
        "        # --- MODIFIED: Spinner Message ---\n",
        "        with st.spinner(f\"Calling LLM via OpenRouter ({DEFAULT_OPENROUTER_MODEL})...\"):\n",
        "        # --- End Modification ---\n",
        "            extracted_result = extract_data_with_llm(st.session_state.ocr_text) # This now calls the OpenRouter version\n",
        "            st.session_state.extracted_data = extracted_result\n",
        "        if isinstance(st.session_state.extracted_data, dict) and st.session_state.extracted_data:\n",
        "            st.write(\"Review and edit the extracted data below:\")\n",
        "\n",
        "        if st.session_state.extracted_data:\n",
        "             if \"raw_llm_output\" in st.session_state.extracted_data:\n",
        "                 # Error message shown in extract_data_with_llm\n",
        "                 st.warning(\"LLM did not return valid JSON. Cannot populate form.\", icon=\"⚠️\")\n",
        "                 st.session_state.extracted_data = {} # Use empty dict\n",
        "             else:\n",
        "                 st.success(\"Data Extraction Attempted by LLM.\", icon=\"🤖\")\n",
        "                 st.write(\"Review and edit the extracted data below:\")\n",
        "        else:\n",
        "             # Error messages shown in extract_data_with_llm\n",
        "             # st.error(\"LLM Data Extraction Failed.\", icon=\"❌\") # Redundant\n",
        "             st.session_state.extracted_data = {} # Use empty dict\n",
        "\n",
        "    # (Confirmation Form logic - No Changes needed here, just uses the result from extract_data_with_llm)\n",
        "    if isinstance(st.session_state.extracted_data, dict) and st.session_state.extracted_data:\n",
        "\n",
        "        with st.form(\"confirmation_form\"):\n",
        "            # ... (Form fields: text_input, text_area, date_input, number_input - remain the same) ...\n",
        "            st.write(\"### Confirm Extracted Details\")\n",
        "            form_data = st.session_state.extracted_data.copy()\n",
        "            c1, c2 = st.columns(2)\n",
        "            with c1:\n",
        "                form_data['buyer_name'] = st.text_input(\"Buyer Name\", value=form_data.get('buyer_name', ''))\n",
        "                form_data['buyer_address'] = st.text_area(\"Buyer Address\", value=form_data.get('buyer_address', ''), height=100)\n",
        "                form_data['buyer_contact'] = st.text_input(\"Buyer Contact\", value=form_data.get('buyer_contact', ''))\n",
        "                default_date_str = form_data.get('receipt_date', '')\n",
        "                default_date = None\n",
        "                if default_date_str:\n",
        "                    try: default_date = datetime.datetime.strptime(default_date_str, '%Y-%m-%d').date()\n",
        "                    except (ValueError, TypeError): st.warning(f\"LLM date '{default_date_str}' not YYYY-MM-DD. Please verify.\", icon=\"⚠️\")\n",
        "                form_data['receipt_date'] = st.date_input(\"Receipt Date\", value=default_date)\n",
        "\n",
        "            with c2:\n",
        "                form_data['store_name'] = st.text_input(\"Store Name\", value=form_data.get('store_name', ''))\n",
        "                form_data['store_address'] = st.text_area(\"Store Address\", value=form_data.get('store_address', ''), height=100)\n",
        "                default_total_val = form_data.get('total_amount')\n",
        "                default_total_float = 0.0\n",
        "                if default_total_val is not None:\n",
        "                    try:\n",
        "                        if isinstance(default_total_val, str): cleaned_val = default_total_val.replace('.', '').replace(',', '')\n",
        "                        else: cleaned_val = default_total_val\n",
        "                        default_total_float = float(cleaned_val)\n",
        "                    except (ValueError, TypeError): st.warning(f\"Could not parse total amount: '{default_total_val}'. Defaulting to 0.0.\", icon=\"⚠️\")\n",
        "                form_data['total_amount'] = st.number_input(\"Total Amount (VND)\", value=default_total_float, format=\"%.0f\", step=1.0)\n",
        "\n",
        "            # ... (Items DataFrame and st.data_editor - remain the same) ...\n",
        "            st.write(\"### Items Purchased\")\n",
        "            items_list = form_data.get('items', [])\n",
        "            if not isinstance(items_list, list):\n",
        "                 st.warning(f\"Items data is not a list (found {type(items_list)}). Displaying empty editor.\", icon=\"⚠️\")\n",
        "                 items_list = []\n",
        "            try:\n",
        "                processed_items = []\n",
        "                required_item_keys = ['description', 'quantity', 'price']\n",
        "                for item in items_list:\n",
        "                    if isinstance(item, dict):\n",
        "                         processed_item = {key: item.get(key) for key in required_item_keys}\n",
        "                         processed_items.append(processed_item)\n",
        "                    else: st.warning(f\"Skipping invalid item data: {item}\", icon=\"⚠️\")\n",
        "                items_df = pd.DataFrame(processed_items)\n",
        "                for col in required_item_keys:\n",
        "                     if col not in items_df.columns: items_df[col] = pd.NA\n",
        "                items_df['description'] = items_df['description'].astype(str).fillna('')\n",
        "                items_df['quantity'] = pd.to_numeric(items_df['quantity'], errors='coerce').fillna(0).astype(int)\n",
        "                items_df['price'] = pd.to_numeric(items_df['price'], errors='coerce').fillna(0.0).astype(float)\n",
        "                items_df = items_df[required_item_keys]\n",
        "            except Exception as df_err:\n",
        "                st.error(f\"Could not create/process DataFrame from items list: {df_err}.\", icon=\"❌\")\n",
        "                items_df = pd.DataFrame(columns=required_item_keys)\n",
        "            edited_items_df = st.data_editor(\n",
        "                items_df, num_rows=\"dynamic\", column_config={\n",
        "                     \"quantity\": st.column_config.NumberColumn(\"Qty\", format=\"%d\", step=1, min_value=0),\n",
        "                     \"price\": st.column_config.NumberColumn(\"Price (VND)\", format=\"%.0f\", step=1.0, min_value=0.0),\n",
        "                     \"description\": st.column_config.TextColumn(\"Description\", width=\"large\", required=True)},\n",
        "                key=\"items_editor\", use_container_width=True)\n",
        "            form_data['items'] = edited_items_df.to_dict('records')\n",
        "\n",
        "            # ... (Form Submission Button and Logic - remain the same, call connect_to_gsheet and append_to_gsheet) ...\n",
        "            submit_button = st.form_submit_button(\n",
        "                 \"Confirm & Save to Google Sheet\", disabled=not gsheet_ready_for_export, use_container_width=True)\n",
        "            if submit_button:\n",
        "                if form_data.get('receipt_date'): form_data['receipt_date'] = form_data['receipt_date'].strftime('%Y-%m-%d')\n",
        "                else: form_data['receipt_date'] = ''\n",
        "                form_data['total_amount'] = form_data.get('total_amount', 0.0)\n",
        "                st.session_state.confirmed_data = form_data\n",
        "                st.write(\"Data confirmed. Attempting to save to Google Sheet...\")\n",
        "                sheet, _ = connect_to_gsheet()\n",
        "                if sheet:\n",
        "                    with st.spinner(\"Appending data to Google Sheet...\"):\n",
        "                        success = append_to_gsheet(sheet, st.session_state.confirmed_data)\n",
        "                        if success: st.success(f\"Data successfully appended to Google Sheet '{GOOGLE_SHEET_NAME}'!\", icon=\"✅\")\n",
        "                        else: st.error(\"Failed to save data to Google Sheet.\", icon=\"❌\")\n",
        "                else: st.error(\"Cannot save data. Google Sheet connection failed.\", icon=\"❌\")\n",
        "\n",
        "    elif run_extraction and not st.session_state.ocr_text:\n",
        "         st.warning(\"Please run OCR first to generate text for extraction.\", icon=\"⚠️\")\n",
        "    elif not st.session_state.extracted_data:\n",
        "        st.info(\"Extracted data will appear here after running LLM extraction.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Launch app via ngrok tunnel\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "NGROK_AUTH_TOKEN = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"Ngrok auth token set.\")\n",
        "else:\n",
        "    print(\"Ngrok auth token not found in .env. Running without token.\")\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.run(['streamlit', 'run', '--server.port', '8501', '--server.headless=true', 'app.py'])\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "public_url = None\n",
        "try:\n",
        "    public_url = ngrok.connect(addr='8501', proto='http')\n",
        "    print(f\"🎉 Your Streamlit app should be available at: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error starting ngrok: {e}\")\n",
        "    print(\"   Streamlit might be running locally but ngrok tunnel failed.\")\n",
        "\n",
        "import time\n",
        "try:\n",
        "    while thread.is_alive():\n",
        "        time.sleep(60)\n",
        "    print(\"Streamlit thread seems to have stopped.\")\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nKeyboardInterrupt received. Shutting down...\")\n",
        "except Exception as e:\n",
        "    print(f\"Exception in keep-alive loop: {e}\")\n",
        "finally:\n",
        "    print(\"Closing ngrok tunnel...\")\n",
        "    if public_url:\n",
        "        try: ngrok.disconnect(public_url); print(\"Ngrok tunnel disconnected.\")\n",
        "        except Exception as ng_e: print(f\"Error disconnecting ngrok: {ng_e}\")\n",
        "    ngrok.kill()\n",
        "    print(\"Ngrok process killed.\")\n",
        "    print(\"Exiting keep-alive loop.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDrccgRbj8oV",
        "outputId": "36406371-a024-4d69-f1ff-4a60668848c7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok auth token set.\n",
            "🎉 Your Streamlit app should be available at: NgrokTunnel: \"https://654a-34-83-108-135.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "KeyboardInterrupt received. Shutting down...\n",
            "Closing ngrok tunnel...\n",
            "Error disconnecting ngrok: ngrok client exception, URLError: [Errno 111] Connection refused\n",
            "Ngrok process killed.\n",
            "Exiting keep-alive loop.\n"
          ]
        }
      ]
    }
  ]
}