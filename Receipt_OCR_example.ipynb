{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJNCi+qXHEFhPHQbXfc0VK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phuocnguyen90/Random-projects/blob/main/Receipt_OCR_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H∆∞·ªõng d·∫´n nhanh s·ª≠ d·ª•ng c√¥ng c·ª• tr√≠ch xu·∫•t h√≥a ƒë∆°n\n",
        "\n",
        "File Google Colab n√†y gi√∫p b·∫°n ƒë·ªçc th√¥ng tin t·ª´ ·∫£nh h√≥a ƒë∆°n v√† l∆∞u v√†o Google Trang t√≠nh (Google Sheet).\n",
        "\n",
        "**C√°c b∆∞·ªõc th·ª±c hi·ªán:**\n",
        "\n",
        "1.  **Ch·∫°y √¥ code #1 (Install dependencies):**\n",
        "    *   T√¨m √¥ code ƒë·∫ßu ti√™n c√≥ ti√™u ƒë·ªÅ `Install dependencies`.\n",
        "    *   Nh·∫•n n√∫t ‚ñ∂Ô∏è (Play) b√™n tr√°i √¥ code ƒë√≥ ƒë·ªÉ b·∫Øt ƒë·∫ßu c√†i ƒë·∫∑t.\n",
        "    *   **Ch·ªù** cho √¥ code ch·∫°y xong (c√≥ th·ªÉ m·∫•t v√†i ph√∫t, ƒë·∫øn khi bi·ªÉu t∆∞·ª£ng ng·ª´ng quay ho·∫∑c c√≥ d·∫•u tick xanh).\n",
        "\n",
        "2.  **Ch·∫°y √¥ code #2 (Authenticate & Setup):**\n",
        "    *   T√¨m √¥ code th·ª© hai (c√≥ ti√™u ƒë·ªÅ `# Authenticate...`).\n",
        "    *   Nh·∫•n n√∫t ‚ñ∂Ô∏è b√™n tr√°i √¥ code.\n",
        "    *   **Nh·∫≠p th√¥ng tin ƒë∆∞·ª£c y√™u c·∫ßu** khi ƒë∆∞·ª£c h·ªèi:\n",
        "        *   `OpenRouter API Key`: C·∫ßn c√≥ ƒë·ªÉ c√¥ng c·ª• hi·ªÉu v√† tr√≠ch xu·∫•t th√¥ng tin h√≥a ƒë∆°n. B·∫°n c√≥ th·ªÉ l·∫•y key mi·ªÖn ph√≠ t·∫°i [https://openrouter.ai/keys](https://openrouter.ai/keys).\n",
        "        *   `(C√°c API Key kh√°c n·∫øu c√≥)`: C·∫ßn c√≥ Ngrok API (mi·ªÖn ph√≠ t·∫°i https://ngrok.com/) ƒë·ªÉ xu·∫•t ƒë∆∞·ªùng link ƒë·∫øn giao di·ªán web. C√≥ th·ªÉ d√πng LLamaparse API key (https://www.llamaindex.ai/llamaparse) ƒë·ªÉ th·ª±c hi·ªán OCR v·ªõi ƒë·ªô ch√≠nh x√°c cao h∆°n\n",
        "        *   `T√™n Google Sheet`: G√µ **t√™n ch√≠nh x√°c** c·ªßa b·∫£ng t√≠nh Google Sheet b·∫°n mu·ªën d√πng ƒë·ªÉ l∆∞u k·∫øt qu·∫£. B·∫£ng t√≠nh n√†y ph·∫£i thu·ªôc t√†i kho·∫£n Google b·∫°n s·∫Ω d√πng ·ªü b∆∞·ªõc sau.\n",
        "    *   M·ªôt **c·ª≠a s·ªï Google s·∫Ω hi·ªán ra**. Ch·ªçn t√†i kho·∫£n Google c·ªßa b·∫°n v√† nh·∫•n **\"Cho ph√©p\" (Allow)** ƒë·ªÉ c·∫•p quy·ªÅn truy c·∫≠p Google Sheet.\n",
        "    \n",
        "    *   L∆∞u √Ω b·∫£o m·∫≠t: ƒê·ªëi v·ªõi ƒëo·∫°n code vi·∫øt s·∫µn n√†y **d·ªØ li·ªáu t·ª´ Google Sheet c·ªßa b·∫°n ƒë∆∞·ª£c b·∫£o m·∫≠t b·ªüi ch√≠nh Google. Tuy nhi√™n n·ªôi dung h√≥a ƒë∆°n ƒë∆∞·ª£c g·ª≠i qua c√°c d·ªãch v·ª• AI kh√°c (Gwen,Meta,Gemma,Deepseek b·∫£n free). C·∫ßn c√¢n nh·∫Øc s·ª≠ d·ª•ng**. B·∫°n c√≥ th·ªÉ t√πy ch·ªânh code ƒë·ªÉ s·ª≠ d·ª•ng ChatGPT API ho·∫∑c local LLM ƒë·ªÉ ƒë·∫£m b·∫£o b·∫£o m·∫≠t d·ªØ li·ªáu h∆°n.\n",
        "\n",
        "    *   Ch·ªù √¥ code ch·∫°y xong v√† b√°o th√†nh c√¥ng (`‚úÖ .env file created successfully`).\n",
        "\n",
        "3.  **Ch·∫°y √¥ code #3 (Write app.py):**\n",
        "    *   Nh·∫•n n√∫t ‚ñ∂Ô∏è b√™n tr√°i √¥ code th·ª© ba ƒë·ªÉ t·∫°o file ·ª©ng d·ª•ng. B∆∞·ªõc n√†y th∆∞·ªùng ch·∫°y r·∫•t nhanh.\n",
        "\n",
        "4.  **Ch·∫°y √¥ code #4 (Run Streamlit):**\n",
        "    *   Nh·∫•n n√∫t ‚ñ∂Ô∏è b√™n tr√°i √¥ code cu·ªëi c√πng ƒë·ªÉ kh·ªüi ƒë·ªông ·ª©ng d·ª•ng web.\n",
        "    *   Ch·ªù m·ªôt l√°t, b·∫°n s·∫Ω th·∫•y m·ªôt d√≤ng ch·ªØ nh∆∞: `Your Streamlit app should be available at: https://....ngrok-free.app`\n",
        "\n",
        "5.  **S·ª≠ d·ª•ng ·ª®ng d·ª•ng Web:**\n",
        "    *   **Nh·∫•p v√†o ƒë∆∞·ªùng link `.app`** v·ª´a xu·∫•t hi·ªán ·ªü tr√™n ƒë·ªÉ m·ªü ·ª©ng d·ª•ng trong tab m·ªõi.\n",
        "    *   Trong trang web ƒë√≥:\n",
        "        *   **T·∫£i l√™n (Upload)** file ·∫£nh h√≥a ƒë∆°n ho·∫∑c PDF t·ª´ m√°y t√≠nh c·ªßa b·∫°n ·ªü c·ªôt b√™n tr√°i.\n",
        "        *   Ch·ªçn ph∆∞∆°ng th·ª©c OCR (th∆∞·ªùng ƒë·ªÉ m·∫∑c ƒë·ªãnh l√† Tesseract).\n",
        "        *   Nh·∫•n n√∫t **\"1. Run OCR\"**. Ch·ªù k·∫øt qu·∫£ OCR xu·∫•t hi·ªán.\n",
        "        *   Nh·∫•n n√∫t **\"2. Extract Data with LLM\"**. Ch·ªù th√¥ng tin ƒë∆∞·ª£c tr√≠ch xu·∫•t ·ªü c·ªôt b√™n ph·∫£i.\n",
        "        *   **Xem l·∫°i v√† ch·ªânh s·ª≠a** th√¥ng tin (n·∫øu c·∫ßn) trong c√°c √¥ ·ªü c·ªôt b√™n ph·∫£i.\n",
        "        *   Cu·ªôn xu·ªëng d∆∞·ªõi c√πng c·ªôt ph·∫£i v√† nh·∫•n n√∫t **\"Confirm & Save to Google Sheet\"** ƒë·ªÉ l∆∞u d·ªØ li·ªáu v√†o Google Sheet c·ªßa b·∫°n.\n",
        "\n",
        "**L∆∞u √Ω:** N·∫øu ·ª©ng d·ª•ng b√°o l·ªói k·∫øt n·ªëi Google Sheet, h√£y quay l·∫°i Colab, ch·∫°y l·∫°i **√¥ code #2** v√† **√¥ code #4**."
      ],
      "metadata": {
        "id": "UoppuYShJDNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Install dependencies (takes 1-2 mins)\n",
        "%%capture\n",
        "# Install system dependencies for Tesseract OCR and PDF processing\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install tesseract-ocr tesseract-ocr-vie poppler-utils -y\n",
        "\n",
        "# Install Python libraries\n",
        "!pip install streamlit pyngrok pytesseract pdf2image paddleocr paddlepaddle openai gspread google-auth google-auth-oauthlib python-dotenv llama-parse Pillow -q\n",
        "\n",
        "# Pillow is usually pre-installed, but explicit install ensures it's there.\n",
        "# Use paddlepaddle (CPU) for simplicity in Colab unless you have a GPU runtime and want GPU acceleration (paddlepaddle-gpu)\n",
        "# llama-parse is used here as an example API parser. Replace/add others if needed.\n",
        "# openai is used for the LLM extraction part. Replace/add others (e.g., anthropic, google-generativeai) if needed."
      ],
      "metadata": {
        "id": "_UZOTZtbv2VJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Authenticate Google User & Setup Environment (Explicit Credential Handling)\n",
        "# Cell 2: Use Colab's pop-up, explicitly get credentials, validate access\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "import gspread\n",
        "from google.colab import auth as colab_auth # Use Colab's auth mechanism\n",
        "import google.auth # <--- Import google.auth to explicitly get credentials\n",
        "from google.auth.exceptions import DefaultCredentialsError\n",
        "import openai\n",
        "import sys\n",
        "\n",
        "# Define scopes required by Sheets and Drive APIs\n",
        "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "\n",
        "print(\"--- User Input & Google Authentication ---\")\n",
        "print(\"Please enter API keys and the Google Sheet name.\")\n",
        "print(\"You will then be prompted via a pop-up to authenticate with Google.\")\n",
        "\n",
        "# --- 1. Get User Inputs ---\n",
        "openrouter_api_key = getpass('Enter your OpenRouter API Key: ')\n",
        "llamaparse_api_key = getpass('Enter your LlamaParse API Key (optional): ')\n",
        "ngrok_auth_token = getpass('Enter your NGROK Auth Token (optional): ')\n",
        "google_sheet_name = input('Enter the exact name of your Google Sheet: ')\n",
        "\n",
        "# --- 2. Perform Google Authentication via Colab ---\n",
        "print(\"\\n--- Authenticating Google User via Colab Pop-up ---\")\n",
        "colab_auth_ok = False\n",
        "try:\n",
        "    colab_auth.authenticate_user() # Trigger the pop-up\n",
        "    print(\"‚úÖ Google User authenticated via Colab pop-up.\")\n",
        "    colab_auth_ok = True\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERROR: Colab authentication failed: {e}\")\n",
        "\n",
        "# --- 3. Explicitly Get Credentials & Validate Sheet Access ---\n",
        "gsheet_access_ok = False\n",
        "apis_enabled_ok = True\n",
        "gspread_client = None # Initialize client variable\n",
        "\n",
        "if colab_auth_ok and google_sheet_name:\n",
        "    print(f\"\\n--- Validating Access to Google Sheet: '{google_sheet_name}' ---\")\n",
        "    try:\n",
        "        # *** Explicitly get default credentials set by Colab auth ***\n",
        "        print(\"Attempting to fetch default credentials...\")\n",
        "        credentials, project_id = google.auth.default(scopes=SCOPES)\n",
        "        print(f\"‚úÖ Successfully fetched default credentials (Project ID: {project_id}).\")\n",
        "\n",
        "        # *** Authorize gspread with the explicit credentials ***\n",
        "        print(\"Authorizing gspread client...\")\n",
        "        gc = gspread.authorize(credentials)\n",
        "        print(\"‚úÖ gspread client authorized.\")\n",
        "        gspread_client = gc # Store client for potential reuse if needed\n",
        "\n",
        "        # *** Open the sheet ***\n",
        "        print(f\"Opening Google Sheet '{google_sheet_name}'...\")\n",
        "        spreadsheet = gc.open(google_sheet_name)\n",
        "        _ = spreadsheet.sheet1.title # Access a property to confirm\n",
        "        gsheet_access_ok = True\n",
        "        print(f\"‚úÖ Successfully accessed Google Sheet '{google_sheet_name}'.\")\n",
        "\n",
        "    except DefaultCredentialsError as e:\n",
        "        # This error means google.auth.default() failed, even after Colab auth\n",
        "        print(f\"‚ùå ERROR: Could not get default credentials after Colab auth: {e}\")\n",
        "        print(\"   Try re-running this cell. If it persists, the Colab environment might have an issue.\")\n",
        "        colab_auth_ok = False # Mark as failed if we can't get creds\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        print(f\"‚ùå ERROR: Google Sheet '{google_sheet_name}' not found OR not shared with the authenticated Colab user.\")\n",
        "    except gspread.exceptions.APIError as e:\n",
        "        apis_enabled_ok = False\n",
        "        print(f\"‚ùå ERROR: Google API Error accessing sheet: {e}\")\n",
        "        if '403' in str(e) or 'PERMISSION_DENIED' in str(e):\n",
        "             print(\"   (Ensure Sheets & Drive APIs are enabled in Google Cloud and the user has permissions).\")\n",
        "    except Exception as e:\n",
        "        # Catch other potential errors during authorize or open\n",
        "        print(f\"‚ùå ERROR: Failed during gspread authorization or sheet opening: {type(e).__name__} - {e}\")\n",
        "\n",
        "elif not google_sheet_name:\n",
        "     print(\"‚ÑπÔ∏è INFO: Google Sheet Name not provided. Skipping sheet access validation.\")\n",
        "elif not colab_auth_ok:\n",
        "     print(\"‚ÑπÔ∏è INFO: Skipping sheet access validation due to failed Colab authentication.\")\n",
        "\n",
        "\n",
        "# --- 4. API Key Validation (OpenRouter & LlamaParse) ---\n",
        "# (This section remains the same as before)\n",
        "print(\"\\n--- API Key Validation ---\")\n",
        "openrouter_ok = False\n",
        "if openrouter_api_key:\n",
        "    print(\"Checking OpenRouter API Key presence...\")\n",
        "    openrouter_ok = True\n",
        "    print(\"‚úÖ OpenRouter API Key provided (basic check).\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è INFO: OpenRouter API Key not provided. LLM extraction will be disabled.\")\n",
        "    openrouter_ok = True # Allow proceeding if key is not provided\n",
        "\n",
        "llamaparse_provided = bool(llamaparse_api_key)\n",
        "if llamaparse_provided: print(\"‚ÑπÔ∏è INFO: LlamaParse API Key provided (basic check only).\")\n",
        "else: print(\"‚ÑπÔ∏è INFO: LlamaParse API Key not provided. LlamaParse option will be disabled.\")\n",
        "\n",
        "\n",
        "# --- 5. Write .env File ---\n",
        "print(\"\\n--- Summary & .env Creation ---\")\n",
        "\n",
        "# Essentials: Colab Auth must succeed AND we must be able to get default creds,\n",
        "# AND ( (sheet name provided AND sheet access ok) OR sheet name not provided )\n",
        "# AND APIs must be enabled (or presumed enabled if access not attempted)\n",
        "essentials_ok = colab_auth_ok and \\\n",
        "                (gsheet_access_ok or not google_sheet_name) and \\\n",
        "                apis_enabled_ok\n",
        "\n",
        "if essentials_ok:\n",
        "    if google_sheet_name and not gsheet_access_ok: print(\"‚ö†Ô∏è WARNING: Google Sheet access validation failed. Streamlit app might fail.\")\n",
        "    elif not google_sheet_name: print(\"‚ÑπÔ∏è INFO: No Google Sheet name provided. Export disabled.\")\n",
        "    else: print(\"‚úÖ Colab authentication and Sheet access validation successful.\")\n",
        "\n",
        "    if not openrouter_ok and openrouter_api_key: print(\"‚ö†Ô∏è WARNING: OpenRouter API Key validation skipped/failed.\")\n",
        "\n",
        "    try:\n",
        "        with open(\".env\", \"w\") as f:\n",
        "            if openrouter_api_key: f.write(f\"OPENROUTER_API_KEY={openrouter_api_key}\\n\")\n",
        "            if llamaparse_api_key: f.write(f\"LLAMAPARSE_API_KEY={llamaparse_api_key}\\n\")\n",
        "            if ngrok_auth_token: f.write(f\"NGROK_AUTH_TOKEN={ngrok_auth_token}\\n\")\n",
        "            if google_sheet_name: f.write(f\"GOOGLE_SHEET_NAME={google_sheet_name}\\n\")\n",
        "\n",
        "        print(\"‚úÖ .env file created successfully.\")\n",
        "        print(\"You can now proceed to run Cell 3 (Write app.py) and Cell 4 (Run Streamlit).\")\n",
        "        print(\"NOTE: If the Streamlit app later shows Google connection errors,\")\n",
        "        print(\"      you may need to re-run this cell to refresh Colab authentication.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERROR: Failed to write .env file: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå ERROR: Essential validation failed. Cannot write .env file.\")\n",
        "    print(\"Please review the errors above and rerun this cell.\")\n",
        "    if not colab_auth_ok: print(\"   - Issue: Google authentication via Colab failed OR could not fetch default credentials after auth.\")\n",
        "    # The error 'Sheet not found...' now implies colab_auth_ok was true, but access failed later\n",
        "    if colab_auth_ok and google_sheet_name and not gsheet_access_ok:\n",
        "        # Distinguish between API not enabled and sheet not found/shared\n",
        "        if not apis_enabled_ok:\n",
        "            print(\"   - Issue: Google Sheets/Drive API likely not enabled or permission issue detected.\")\n",
        "        else:\n",
        "            print(\"   - Issue: Google Sheet not found or not shared correctly with the authenticated user.\")\n",
        "    # Check OpenRouter only if it was the reason for failure (less likely)\n",
        "    # if not openrouter_ok: print(\"   - Issue: OpenRouter validation failed (if applicable).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "uVdu9kdt42NY",
        "outputId": "761c0571-d3f0-4e67-ed29-2f36c230412b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- User Input & Google Authentication ---\n",
            "Please enter API keys and the Google Sheet name.\n",
            "You will then be prompted via a pop-up to authenticate with Google.\n",
            "Enter your OpenRouter API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Enter your LlamaParse API Key (optional): ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Enter your NGROK Auth Token (optional): ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Enter the exact name of your Google Sheet: receipt\n",
            "\n",
            "--- Authenticating Google User via Colab Pop-up ---\n",
            "‚úÖ Google User authenticated via Colab pop-up.\n",
            "\n",
            "--- Validating Access to Google Sheet: 'receipt' ---\n",
            "Attempting to fetch default credentials...\n",
            "‚úÖ Successfully fetched default credentials (Project ID: ).\n",
            "Authorizing gspread client...\n",
            "‚úÖ gspread client authorized.\n",
            "Opening Google Sheet 'receipt'...\n",
            "‚úÖ Successfully accessed Google Sheet 'receipt'.\n",
            "\n",
            "--- API Key Validation ---\n",
            "Checking OpenRouter API Key presence...\n",
            "‚úÖ OpenRouter API Key provided (basic check).\n",
            "‚ÑπÔ∏è INFO: LlamaParse API Key not provided. LlamaParse option will be disabled.\n",
            "\n",
            "--- Summary & .env Creation ---\n",
            "‚úÖ Colab authentication and Sheet access validation successful.\n",
            "‚úÖ .env file created successfully.\n",
            "You can now proceed to run Cell 3 (Write app.py) and Cell 4 (Run Streamlit).\n",
            "NOTE: If the Streamlit app later shows Google connection errors,\n",
            "      you may need to re-run this cell to refresh Colab authentication.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ASc1NpEiwY4",
        "outputId": "5bb467ea-6ac0-435e-a071-aa5dab64191d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "# @title 3. Write app.py\n",
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_bytes\n",
        "from paddleocr import PaddleOCR\n",
        "import openai\n",
        "import gspread\n",
        "import google.auth # <--- Import google.auth\n",
        "from google.auth.exceptions import DefaultCredentialsError\n",
        "from llama_parse import LlamaParse\n",
        "from dotenv import load_dotenv\n",
        "import io\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import asyncio\n",
        "\n",
        "\n",
        "\n",
        "# --- Page Config MUST BE THE FIRST STREAMLIT COMMAND ---\n",
        "st.set_page_config(layout=\"wide\")\n",
        "\n",
        "# --- Configuration & Initialization ---\n",
        "load_dotenv()\n",
        "\n",
        "# --- MODIFIED: Load OpenRouter Key ---\n",
        "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "# --- End Modification ---\n",
        "LLAMAPARSE_API_KEY = os.getenv(\"LLAMAPARSE_API_KEY\")\n",
        "GOOGLE_SHEET_NAME = os.getenv(\"GOOGLE_SHEET_NAME\")\n",
        "NGROK_AUTH_TOKEN = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "# --- Add OpenRouter Configuration ---\n",
        "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "FREE_ROUTER_MODELS = [\n",
        "    \"qwen/qwen2.5-vl-32b-instruct:free\", # Most likely to support JSON mode from this list\n",
        "    \"meta-llama/llama-4-scout:free\",\n",
        "    \"google/gemma-3-12b-it:free\",\n",
        "    \"deepseek/deepseek-v3-base:free\",\n",
        "]\n",
        "\n",
        "# Define the model to use on OpenRouter (must match their naming)\n",
        "# Examples: \"openai/gpt-4o\", \"google/gemini-pro-1.5\", \"anthropic/claude-3-haiku\"\n",
        "# Let's default to gpt-4o via OpenRouter\n",
        "DEFAULT_OPENROUTER_MODEL = os.getenv(\"OPENROUTER_MODEL\", \"meta-llama/llama-4-scout:free\")\n",
        "\n",
        "# Define scopes needed by gspread\n",
        "GSPREAD_SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "\n",
        "\n",
        "# --- Initialize OpenRouter Client (using openai library structure) ---\n",
        "openrouter_client = None\n",
        "if OPENROUTER_API_KEY:\n",
        "    try:\n",
        "\n",
        "        openrouter_client = openai.OpenAI(\n",
        "            base_url=OPENROUTER_BASE_URL,\n",
        "            api_key=OPENROUTER_API_KEY,\n",
        "            # default_headers=headers # Uncomment to add headers\n",
        "        )\n",
        "        print(\"OpenRouter client initialized.\") # Log for server console\n",
        "    except Exception as e:\n",
        "\n",
        "        st.error(f\"Failed to initialize OpenRouter client: {e}\", icon=\"‚ùå\")\n",
        "# --- End Client Initialization ---\n",
        "\n",
        "\n",
        "# --- Helper Functions (OCR, PDF, LlamaParse remain the same) ---\n",
        "\n",
        "def process_image_tesseract(image_bytes):\n",
        "    \"\"\"Performs OCR on image bytes using Tesseract for Vietnamese.\"\"\"\n",
        "    try:\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        text = pytesseract.image_to_string(image, lang='vie')\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Tesseract OCR failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_pdf_tesseract(pdf_bytes):\n",
        "    \"\"\"Converts PDF to images and performs OCR using Tesseract for Vietnamese.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        images = convert_from_bytes(pdf_bytes)\n",
        "        for i, image in enumerate(images):\n",
        "            # st.write(f\"Processing PDF page {i+1} with Tesseract (Vietnamese)...\") # Reduce noise\n",
        "            text += pytesseract.image_to_string(image, lang='vie') + \"\\n\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Tesseract PDF processing failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_image_paddle(image_bytes, paddle_ocr_instance):\n",
        "    \"\"\"Performs OCR on image bytes using PaddleOCR (already configured for Vietnamese).\"\"\"\n",
        "    if paddle_ocr_instance is None:\n",
        "        st.error(\"PaddleOCR is not initialized.\")\n",
        "        return None\n",
        "    try:\n",
        "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "        image_np = np.array(image)\n",
        "        result = paddle_ocr_instance.ocr(image_np, cls=True)\n",
        "        text = \"\"\n",
        "        if result and result[0]:\n",
        "            for line in result[0]:\n",
        "                text += line[1][0] + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"PaddleOCR failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_pdf_paddle(pdf_bytes, paddle_ocr_instance):\n",
        "    \"\"\"Converts PDF to images and performs OCR using PaddleOCR (already configured for Vietnamese).\"\"\"\n",
        "    if paddle_ocr_instance is None:\n",
        "        st.error(\"PaddleOCR is not initialized.\")\n",
        "        return None\n",
        "    text = \"\"\n",
        "    try:\n",
        "        images = convert_from_bytes(pdf_bytes)\n",
        "        for i, image in enumerate(images):\n",
        "            # st.write(f\"Processing PDF page {i+1} with PaddleOCR (Vietnamese)...\") # Reduce noise\n",
        "            image_np = np.array(image.convert(\"RGB\"))\n",
        "            result = paddle_ocr_instance.ocr(image_np, cls=True)\n",
        "            if result and result[0]:\n",
        "                for line in result[0]:\n",
        "                    text += line[1][0] + \"\\n\"\n",
        "            text += \"\\n\\n\" # Add separator between pages\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"PaddleOCR PDF processing failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_file_llamaparse(file_bytes, filename, parser_instance):\n",
        "    \"\"\"Uses LlamaParse API to extract text from image or PDF.\"\"\"\n",
        "    if parser_instance is None:\n",
        "        # Error/info message handled in sidebar based on key presence/init status\n",
        "        # st.error(\"LlamaParse parser not initialized.\")\n",
        "        return None\n",
        "    temp_filepath = None\n",
        "    try:\n",
        "        # Ensure temp file has extension if needed by parser\n",
        "        _, extension = os.path.splitext(filename)\n",
        "        temp_filepath = f\"./temp_llamaparse{extension}\"\n",
        "        with open(temp_filepath, \"wb\") as f:\n",
        "            f.write(file_bytes)\n",
        "\n",
        "        # Handle asyncio event loop for Streamlit\n",
        "        try:\n",
        "            loop = asyncio.get_event_loop_policy().get_event_loop()\n",
        "            # Use loop.is_running() check if needed, but run_until_complete usually handles it\n",
        "        except RuntimeError:\n",
        "            loop = asyncio.new_event_loop()\n",
        "            asyncio.set_event_loop(loop)\n",
        "\n",
        "        # Await the async call correctly\n",
        "        documents = loop.run_until_complete(parser_instance.aload_data(temp_filepath))\n",
        "\n",
        "        if documents:\n",
        "            # Combine text from potentially multiple documents LlamaParse might return\n",
        "            full_text = \"\\n\\n\".join([doc.text for doc in documents])\n",
        "            return full_text\n",
        "        else:\n",
        "             st.warning(\"LlamaParse returned no documents.\", icon=\"‚ö†Ô∏è\")\n",
        "             return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"LlamaParse API call failed: {e}\", icon=\"‚ùå\")\n",
        "        return None\n",
        "    finally:\n",
        "        if temp_filepath and os.path.exists(temp_filepath):\n",
        "            try:\n",
        "                os.remove(temp_filepath)\n",
        "            except OSError as e:\n",
        "                st.warning(f\"Could not remove temporary file {temp_filepath}: {e}\", icon=\"‚ö†Ô∏è\")\n",
        "\n",
        "# --- MODIFIED: extract_data_with_llm function (Model Routing Logic) ---\n",
        "def extract_data_with_llm(text):\n",
        "    \"\"\"Uses OpenRouter with model routing to extract structured data.\"\"\"\n",
        "    global openrouter_client\n",
        "    if not openrouter_client:\n",
        "        st.error(\"OpenRouter client not initialized. Check API Key.\", icon=\"‚ùó\")\n",
        "        return None\n",
        "    if not text or not text.strip():\n",
        "        st.warning(\"No text provided for extraction.\", icon=\"‚ö†Ô∏è\")\n",
        "        return None\n",
        "\n",
        "    # The prompt remains the same\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert assistant specialized in extracting information from Vietnamese receipts.\n",
        "    The following text was extracted from a receipt, likely in Vietnamese.\n",
        "    Extract the key information and format the output as a single JSON object.\n",
        "    Use the exact English keys provided below. If a value is not found, use null or an empty string \"\".\n",
        "\n",
        "    Keys to extract:\n",
        "    - 'buyer_name': Name of the customer/buyer (T√™n kh√°ch h√†ng).\n",
        "    - 'buyer_address': Address of the customer/buyer (ƒê·ªãa ch·ªâ kh√°ch h√†ng).\n",
        "    - 'buyer_contact': Phone number or email of the customer/buyer (SƒêT/Email kh√°ch h√†ng).\n",
        "    - 'receipt_date': Date the receipt was issued (Ng√†y h√≥a ƒë∆°n). Format this as YYYY-MM-DD. If the date is like DD/MM/YYYY or DD-MM-YYYY, convert it.\n",
        "    - 'store_name': Name of the store/vendor (T√™n c·ª≠a h√†ng / ƒê∆°n v·ªã b√°n).\n",
        "    - 'store_address': Address of the store/vendor (ƒê·ªãa ch·ªâ c·ª≠a h√†ng).\n",
        "    - 'total_amount': The final total amount paid (T·ªïng c·ªông / T·ªïng thanh to√°n). Provide only the numerical value, removing currency symbols like 'ƒë' or 'VND' and thousand separators like '.' or ','.\n",
        "    - 'items': A list of items purchased. Each item MUST be an object with 'description' (T√™n h√†ng / M√¥ t·∫£), 'quantity' (S·ªë l∆∞·ª£ng - SL), and 'price' (ƒê∆°n gi√° or Th√†nh ti·ªÅn). Extract numerical values for quantity and price.\n",
        "\n",
        "    Important Notes:\n",
        "    - The text is in Vietnamese. Pay attention to Vietnamese names, addresses, and date formats (DD/MM/YYYY).\n",
        "    - For 'total_amount', 'quantity', and 'price', extract only numbers. Handle separators (like '.' for thousands in VND) correctly. For example, '50.000 ƒë' should become 50000.\n",
        "    - Output only the JSON object, nothing else before or after it.\n",
        "\n",
        "    Receipt Text (Vietnamese):\n",
        "    ---\n",
        "    {text}\n",
        "    ---\n",
        "\n",
        "    JSON Output:\n",
        "    \"\"\"\n",
        "\n",
        "    extracted_data = None\n",
        "    last_error = None\n",
        "    last_error_model = None\n",
        "    successful_model = None\n",
        "\n",
        "    # Optionally shuffle the list each time to distribute load\n",
        "    # current_model_list = random.sample(FREE_ROUTER_MODELS, len(FREE_ROUTER_MODELS))\n",
        "    current_model_list = FREE_ROUTER_MODELS # Or use the fixed order\n",
        "\n",
        "    st.info(f\"Attempting extraction using free models: {', '.join(current_model_list)}\")\n",
        "\n",
        "    for model_name in current_model_list:\n",
        "        st.write(f\"Trying model: `{model_name}`...\") # Give feedback on attempts\n",
        "        content = None # Reset content for each model attempt\n",
        "        try:\n",
        "            response = openrouter_client.chat.completions.create(\n",
        "                model=model_name, # Use the current model from the list\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert receipt data extraction assistant specializing in Vietnamese documents.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                response_format={\"type\": \"json_object\"}, # Attempt JSON mode\n",
        "                temperature=0.1,\n",
        "                # Add a timeout? e.g., timeout=30.0\n",
        "            )\n",
        "            content = response.choices[0].message.content\n",
        "\n",
        "            # Try parsing the JSON\n",
        "            try:\n",
        "                extracted_data = json.loads(content)\n",
        "                # Basic validation: Check if it's a dictionary\n",
        "                if isinstance(extracted_data, dict):\n",
        "                    st.success(f\"‚úÖ Successfully extracted data using `{model_name}`!\")\n",
        "                    successful_model = model_name\n",
        "                    break # Exit loop on first successful extraction and parse\n",
        "                else:\n",
        "                    st.warning(f\"‚ö†Ô∏è Model `{model_name}` returned valid JSON, but it wasn't a dictionary. Trying next.\", icon=\"‚ö†Ô∏è\")\n",
        "                    last_error = f\"Returned non-dict JSON: {content[:100]}...\"\n",
        "                    last_error_model = model_name\n",
        "                    extracted_data = None # Reset data as it wasn't the expected type\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                st.warning(f\"‚ö†Ô∏è Model `{model_name}` returned invalid JSON. Trying next.\", icon=\"‚ö†Ô∏è\")\n",
        "                # Optionally show the invalid JSON\n",
        "                # with st.expander(f\"Invalid JSON from {model_name}\"):\n",
        "                #    st.code(content, language=None)\n",
        "                last_error = f\"Invalid JSON: {content[:100]}...\"\n",
        "                last_error_model = model_name\n",
        "                # Keep extracted_data as None and continue loop\n",
        "\n",
        "        except openai.AuthenticationError as e:\n",
        "             st.error(\"OpenRouter Authentication Error: Invalid API Key?\", icon=\"‚ùó\")\n",
        "             return None # Auth errors are fatal, no point trying other models\n",
        "        except openai.RateLimitError as e:\n",
        "             st.warning(f\"‚è≥ Rate limit hit for `{model_name}`. Trying next...\", icon=\"‚è≥\")\n",
        "             last_error = e\n",
        "             last_error_model = model_name\n",
        "             continue # Try the next model\n",
        "        except openai.APITimeoutError as e:\n",
        "             st.warning(f\"‚è≥ Timeout connecting to `{model_name}`. Trying next...\", icon=\"‚è≥\")\n",
        "             last_error = e\n",
        "             last_error_model = model_name\n",
        "             continue\n",
        "        except openai.APIError as e: # Catch other OpenRouter/model-specific API errors\n",
        "            st.warning(f\"‚ùå API Error with `{model_name}` (Code: {e.status_code}): {e.message}. Trying next...\", icon=\"‚ùå\")\n",
        "            last_error = e\n",
        "            last_error_model = model_name\n",
        "            continue # Try the next model\n",
        "        except Exception as e:\n",
        "            st.warning(f\"‚ö†Ô∏è Unexpected error with `{model_name}`: {type(e).__name__}. Trying next...\", icon=\"‚ö†Ô∏è\")\n",
        "            last_error = e\n",
        "            last_error_model = model_name\n",
        "            continue # Try the next model\n",
        "\n",
        "    # After the loop completes\n",
        "    if successful_model:\n",
        "        return extracted_data # Return the successfully parsed data\n",
        "    else:\n",
        "        st.error(\"‚ùå All attempted free models failed to extract valid data.\", icon=\"‚ùå\")\n",
        "        if last_error:\n",
        "            st.caption(f\"Last error encountered (with `{last_error_model}`): {last_error}\")\n",
        "        return None # Indicate failure\n",
        "\n",
        "# --- Google Sheet Functions (get_gspread_client, connect_to_gsheet, append_to_gsheet remain the same) ---\n",
        "@st.cache_resource(ttl=600)\n",
        "def get_gspread_client():\n",
        "    \"\"\"Attempts to get an authorized gspread client using explicit default credentials.\"\"\"\n",
        "    try:\n",
        "        # Explicitly get default credentials set by Colab auth\n",
        "        credentials, project = google.auth.default(scopes=GSPREAD_SCOPES)\n",
        "        # *** Authorize gspread with the explicit credentials ***\n",
        "        client = gspread.authorize(credentials) # <--- THE CORRECTION\n",
        "        st.success(\"Successfully obtained Google API client via Colab credentials.\", icon=\"‚úÖ\")\n",
        "        return client\n",
        "    except DefaultCredentialsError:\n",
        "        st.error(\"‚ùå Google Credentials not found by application.\", icon=\"üö®\")\n",
        "        st.warning(\"üí° Please run the 'Authenticate Google User' cell in Colab and RESTART this Streamlit app.\", icon=\"üí°\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Failed to initialize Google client: {type(e).__name__} - {e}\", icon=\"üö®\")\n",
        "        return None\n",
        "\n",
        "def connect_to_gsheet():\n",
        "    \"\"\"Connects to the specified Google Sheet.\"\"\"\n",
        "    if not GOOGLE_SHEET_NAME: st.warning(\"Sheet Name missing.\", icon=\"‚ö†Ô∏è\"); return None, None\n",
        "    client = get_gspread_client() # Uses the corrected function\n",
        "    if client:\n",
        "        try: spreadsheet = client.open(GOOGLE_SHEET_NAME); sheet = spreadsheet.sheet1; return sheet, client\n",
        "        except gspread.exceptions.SpreadsheetNotFound: st.error(f\"‚ùå Sheet '{GOOGLE_SHEET_NAME}' not found/shared.\", icon=\"üö®\"); return None, None\n",
        "        except gspread.exceptions.APIError as e: st.error(f\"‚ùå Google API Error: {e}.\", icon=\"üö®\"); return None, None\n",
        "        except Exception as e: st.error(f\"‚ùå Failed to open Sheet: {e}\", icon=\"üö®\"); return None, None\n",
        "    else: return None, None # Error handled in get_gspread_client\n",
        "\n",
        "\n",
        "def append_to_gsheet(sheet, data):\n",
        "    \"\"\"Appends extracted data as a new row in the Google Sheet.\"\"\"\n",
        "    # ... (This function's logic remains exactly the same) ...\n",
        "    try:\n",
        "        headers = [\n",
        "            'Extraction Date', 'Buyer Name', 'Buyer Address', 'Buyer Contact',\n",
        "            'Receipt Date', 'Store Name', 'Store Address', 'Total Amount',\n",
        "            'Items JSON'\n",
        "        ]\n",
        "        header_row = []\n",
        "        try:\n",
        "            header_row = sheet.row_values(1)\n",
        "        except gspread.exceptions.APIError as e:\n",
        "             if 'PERMISSION_DENIED' in str(e) or '403' in str(e):\n",
        "                 st.warning(f\"Could not read header row (Permission Denied: {e}). Assuming headers exist or sheet is empty. Attempting to append.\", icon=\"‚ö†Ô∏è\")\n",
        "             else:\n",
        "                st.warning(f\"Could not read header row ({e}). Assuming sheet is empty.\", icon=\"‚ö†Ô∏è\")\n",
        "                header_row = []\n",
        "\n",
        "        if not header_row:\n",
        "             try:\n",
        "                 sheet.append_row(headers, value_input_option='USER_ENTERED')\n",
        "                 st.info(\"Added header row to Google Sheet.\", icon=\"‚ÑπÔ∏è\")\n",
        "             except gspread.exceptions.APIError as append_e:\n",
        "                 st.error(f\"Failed to add header row: {append_e}. Check sheet write permissions.\", icon=\"‚ùå\")\n",
        "                 return False\n",
        "        elif header_row != headers:\n",
        "             st.warning(\"Sheet headers don't match expected headers. Appending based on defined order. Please check your Google Sheet columns.\", icon=\"‚ö†Ô∏è\")\n",
        "\n",
        "        row_to_append = [\n",
        "            datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            data.get('buyer_name', ''),\n",
        "            data.get('buyer_address', ''),\n",
        "            data.get('buyer_contact', ''),\n",
        "            data.get('receipt_date', ''),\n",
        "            data.get('store_name', ''),\n",
        "            data.get('store_address', ''),\n",
        "            data.get('total_amount', ''),\n",
        "            json.dumps(data.get('items', []), ensure_ascii=False)\n",
        "        ]\n",
        "        sheet.append_row(row_to_append, value_input_option='USER_ENTERED')\n",
        "        return True\n",
        "    except gspread.exceptions.APIError as e:\n",
        "         st.error(f\"Google Sheets API error during append: {e}\", icon=\"‚ùå\")\n",
        "         return False\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to append data to Google Sheet: {e}\", icon=\"‚ùå\")\n",
        "        return False\n",
        "\n",
        "# --- Initialize OCR/Parser Clients (Paddle, LlamaParse remain the same) ---\n",
        "@st.cache_resource\n",
        "def get_paddle_ocr():\n",
        "    try:\n",
        "        paddle_ocr_instance = PaddleOCR(use_angle_cls=True, lang='vi', use_gpu=False, show_log=False)\n",
        "        print(\"PaddleOCR initialized successfully for Vietnamese.\")\n",
        "        return paddle_ocr_instance\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Could not initialize PaddleOCR: {e}. PaddleOCR option will be disabled.\", icon=\"‚ö†Ô∏è\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource\n",
        "def get_llama_parser():\n",
        "    if LLAMAPARSE_API_KEY:\n",
        "        try:\n",
        "            parser_instance = LlamaParse(api_key=LLAMAPARSE_API_KEY, result_type=\"text\")\n",
        "            print(\"LlamaParse parser initialized successfully.\")\n",
        "            return parser_instance\n",
        "        except Exception as e:\n",
        "             st.warning(f\"Could not initialize LlamaParse: {e}. LlamaParse option disabled.\", icon=\"‚ö†Ô∏è\")\n",
        "             return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "paddle_ocr_instance = get_paddle_ocr()\n",
        "llama_parser_instance = get_llama_parser()\n",
        "\n",
        "# --- Streamlit App UI ---\n",
        "st.title(\"üßæ Vietnamese Receipt OCR & Data Extraction (OpenRouter LLM)\") # Updated Title\n",
        "st.info(f\"Uses Colab Auth for GSheets & OpenRouter ({DEFAULT_OPENROUTER_MODEL}) for LLM extraction.\")\n",
        "\n",
        "# Initialize session state (remains the same)\n",
        "# ... (ocr_text, extracted_data, etc.) ...\n",
        "if 'ocr_text' not in st.session_state: st.session_state.ocr_text = None\n",
        "if 'extracted_data' not in st.session_state: st.session_state.extracted_data = None\n",
        "if 'file_processed' not in st.session_state: st.session_state.file_processed = False\n",
        "if 'confirmed_data' not in st.session_state: st.session_state.confirmed_data = None\n",
        "\n",
        "\n",
        "# --- Sidebar for Configuration ---\n",
        "with st.sidebar:\n",
        "    st.header(\"Configuration\")\n",
        "    uploaded_file = st.file_uploader(\"Upload Receipt (Image or PDF)\", type=[\"png\", \"jpg\", \"jpeg\", \"pdf\"])\n",
        "\n",
        "    # (OCR Method Selection - Remains the same)\n",
        "    ocr_options = ['Tesseract (Local)']\n",
        "    if paddle_ocr_instance: ocr_options.insert(0, 'PaddleOCR (Local)')\n",
        "    else: st.warning(\"PaddleOCR option disabled (initialization failed).\", icon=\"‚ö†Ô∏è\")\n",
        "    if llama_parser_instance: ocr_options.append('LlamaParse (API)')\n",
        "    elif LLAMAPARSE_API_KEY: st.warning(\"LlamaParse option disabled (initialization failed).\", icon=\"‚ö†Ô∏è\")\n",
        "\n",
        "\n",
        "    default_ocr_index = 0 # Default to 0 (Tesseract)\n",
        "    tesseract_label = 'Tesseract (Local)'\n",
        "    if tesseract_label in ocr_options:\n",
        "        try:\n",
        "            default_ocr_index = ocr_options.index(tesseract_label)\n",
        "        except ValueError:\n",
        "            pass # Should not happen as we always add it, but safer\n",
        "\n",
        "\n",
        "    if not ocr_options:\n",
        "         st.error(\"No OCR engines available!\", icon=\"‚ùå\")\n",
        "         ocr_method = None\n",
        "    else:\n",
        "         default_ocr_index = 0\n",
        "         ocr_method = st.radio(\"Choose OCR Method:\", options=ocr_options, index=default_ocr_index)\n",
        "\n",
        "    run_ocr = st.button(\"1. Run OCR\", disabled=(uploaded_file is None or ocr_method is None), use_container_width=True)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    # --- MODIFIED: LLM Extraction Button Check ---\n",
        "    openrouter_ready = bool(openrouter_client) # Check if client initialized successfully\n",
        "    extract_button_disabled = (not st.session_state.get('ocr_text') or not openrouter_ready)\n",
        "    run_extraction = st.button(\"2. Extract Data with LLM\",\n",
        "                               disabled=extract_button_disabled,\n",
        "                               use_container_width=True)\n",
        "    if not openrouter_ready:\n",
        "         st.error(\"OpenRouter API Key missing or invalid. LLM Extraction disabled.\", icon=\"‚ùó\")\n",
        "    # --- End Modification ---\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    # (Google Sheet Config Info - Remains the same)\n",
        "    st.header(\"Google Sheet Export\")\n",
        "    gsheet_ready_for_export = False # Default to false\n",
        "    if GOOGLE_SHEET_NAME:\n",
        "        st.info(f\"Target Sheet: '{GOOGLE_SHEET_NAME}'\", icon=\"üìÑ\")\n",
        "        client_check = get_gspread_client() # Check connection status\n",
        "        gsheet_ready_for_export = client_check is not None\n",
        "\n",
        "    else:\n",
        "        st.info(\"No Google Sheet name configured.\", icon=\"‚ÑπÔ∏è\")\n",
        "\n",
        "\n",
        "# --- Main Area ---\n",
        "# (OCR Execution logic remains the same)\n",
        "# (Extracted Data & Confirmation Form logic remains the same, but relies on the modified extract_data_with_llm)\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    # Display Uploaded File & Run OCR Logic\n",
        "    st.subheader(\"Uploaded File & OCR Text\")\n",
        "    if uploaded_file is not None:\n",
        "        file_bytes = uploaded_file.getvalue()\n",
        "        file_name = uploaded_file.name\n",
        "        file_type = uploaded_file.type\n",
        "\n",
        "        if file_type.startswith(\"image\"):\n",
        "            try:\n",
        "                st.image(file_bytes, caption=\"Uploaded Receipt Image\", use_column_width=True)\n",
        "            except Exception as img_e:\n",
        "                st.warning(f\"Could not display image preview: {img_e}\", icon=\"‚ö†Ô∏è\")\n",
        "        elif file_type == \"application/pdf\":\n",
        "            st.info(f\"Uploaded PDF: {file_name}.\", icon=\"üìÑ\")\n",
        "\n",
        "        if run_ocr and ocr_method:\n",
        "            # Reset states before running\n",
        "            st.session_state.ocr_text = None\n",
        "            st.session_state.extracted_data = None\n",
        "            st.session_state.confirmed_data = None\n",
        "            st.session_state.file_processed = True # Mark that processing was attempted\n",
        "            ocr_output = None # Temp variable\n",
        "\n",
        "            with st.spinner(f\"Running {ocr_method}...\"):\n",
        "                if ocr_method == 'Tesseract (Local)':\n",
        "                    if file_type.startswith(\"image\"): ocr_output = process_image_tesseract(file_bytes)\n",
        "                    elif file_type == \"application/pdf\": ocr_output = process_pdf_tesseract(file_bytes)\n",
        "                elif ocr_method == 'PaddleOCR (Local)':\n",
        "                    if file_type.startswith(\"image\"): ocr_output = process_image_paddle(file_bytes, paddle_ocr_instance)\n",
        "                    elif file_type == \"application/pdf\": ocr_output = process_pdf_paddle(file_bytes, paddle_ocr_instance)\n",
        "                elif ocr_method == 'LlamaParse (API)':\n",
        "                     ocr_output = process_file_llamaparse(file_bytes, file_name, llama_parser_instance)\n",
        "\n",
        "            st.session_state.ocr_text = ocr_output # Assign result to session state\n",
        "\n",
        "            if st.session_state.ocr_text and st.session_state.ocr_text.strip():\n",
        "                st.success(\"OCR Completed!\", icon=\"‚úÖ\")\n",
        "                # --- Force rerun to update button state ---\n",
        "                st.rerun()\n",
        "                # --- End force rerun ---\n",
        "            else:\n",
        "                st.error(\"OCR failed or produced no text.\", icon=\"‚ùå\")\n",
        "                # No rerun needed if OCR failed, button should remain disabled\n",
        "        # --- End Run OCR Logic Modification ---\n",
        "\n",
        "    if st.session_state.ocr_text:\n",
        "        st.text_area(\"OCR Output\", st.session_state.ocr_text, height=350, key=\"ocr_output_area\")\n",
        "    elif st.session_state.file_processed and not st.session_state.ocr_text:\n",
        "          st.warning(\"No OCR text was generated from the file.\", icon=\"‚ö†Ô∏è\")\n",
        "\n",
        "with col2:\n",
        "    st.subheader(\"Extracted Data & Confirmation\")\n",
        "\n",
        "    if run_extraction and st.session_state.ocr_text:\n",
        "        st.session_state.extracted_data = None\n",
        "        st.session_state.confirmed_data = None\n",
        "        # --- MODIFIED: Spinner Message ---\n",
        "        with st.spinner(f\"Calling LLM via OpenRouter ({DEFAULT_OPENROUTER_MODEL})...\"):\n",
        "        # --- End Modification ---\n",
        "            extracted_result = extract_data_with_llm(st.session_state.ocr_text) # This now calls the OpenRouter version\n",
        "            st.session_state.extracted_data = extracted_result\n",
        "        if isinstance(st.session_state.extracted_data, dict) and st.session_state.extracted_data:\n",
        "            st.write(\"Review and edit the extracted data below:\")\n",
        "\n",
        "        if st.session_state.extracted_data:\n",
        "             if \"raw_llm_output\" in st.session_state.extracted_data:\n",
        "                 # Error message shown in extract_data_with_llm\n",
        "                 st.warning(\"LLM did not return valid JSON. Cannot populate form.\", icon=\"‚ö†Ô∏è\")\n",
        "                 st.session_state.extracted_data = {} # Use empty dict\n",
        "             else:\n",
        "                 st.success(\"Data Extraction Attempted by LLM.\", icon=\"ü§ñ\")\n",
        "                 st.write(\"Review and edit the extracted data below:\")\n",
        "        else:\n",
        "             # Error messages shown in extract_data_with_llm\n",
        "             # st.error(\"LLM Data Extraction Failed.\", icon=\"‚ùå\") # Redundant\n",
        "             st.session_state.extracted_data = {} # Use empty dict\n",
        "\n",
        "    # (Confirmation Form logic - No Changes needed here, just uses the result from extract_data_with_llm)\n",
        "    if isinstance(st.session_state.extracted_data, dict) and st.session_state.extracted_data:\n",
        "\n",
        "        with st.form(\"confirmation_form\"):\n",
        "            # ... (Form fields: text_input, text_area, date_input, number_input - remain the same) ...\n",
        "            st.write(\"### Confirm Extracted Details\")\n",
        "            form_data = st.session_state.extracted_data.copy()\n",
        "            c1, c2 = st.columns(2)\n",
        "            with c1:\n",
        "                form_data['buyer_name'] = st.text_input(\"Buyer Name\", value=form_data.get('buyer_name', ''))\n",
        "                form_data['buyer_address'] = st.text_area(\"Buyer Address\", value=form_data.get('buyer_address', ''), height=100)\n",
        "                form_data['buyer_contact'] = st.text_input(\"Buyer Contact\", value=form_data.get('buyer_contact', ''))\n",
        "                default_date_str = form_data.get('receipt_date', '')\n",
        "                default_date = None\n",
        "                if default_date_str:\n",
        "                    try: default_date = datetime.datetime.strptime(default_date_str, '%Y-%m-%d').date()\n",
        "                    except (ValueError, TypeError): st.warning(f\"LLM date '{default_date_str}' not YYYY-MM-DD. Please verify.\", icon=\"‚ö†Ô∏è\")\n",
        "                form_data['receipt_date'] = st.date_input(\"Receipt Date\", value=default_date)\n",
        "\n",
        "            with c2:\n",
        "                form_data['store_name'] = st.text_input(\"Store Name\", value=form_data.get('store_name', ''))\n",
        "                form_data['store_address'] = st.text_area(\"Store Address\", value=form_data.get('store_address', ''), height=100)\n",
        "                default_total_val = form_data.get('total_amount')\n",
        "                default_total_float = 0.0\n",
        "                if default_total_val is not None:\n",
        "                    try:\n",
        "                        if isinstance(default_total_val, str): cleaned_val = default_total_val.replace('.', '').replace(',', '')\n",
        "                        else: cleaned_val = default_total_val\n",
        "                        default_total_float = float(cleaned_val)\n",
        "                    except (ValueError, TypeError): st.warning(f\"Could not parse total amount: '{default_total_val}'. Defaulting to 0.0.\", icon=\"‚ö†Ô∏è\")\n",
        "                form_data['total_amount'] = st.number_input(\"Total Amount (VND)\", value=default_total_float, format=\"%.0f\", step=1.0)\n",
        "\n",
        "            # ... (Items DataFrame and st.data_editor - remain the same) ...\n",
        "            st.write(\"### Items Purchased\")\n",
        "            items_list = form_data.get('items', [])\n",
        "            if not isinstance(items_list, list):\n",
        "                 st.warning(f\"Items data is not a list (found {type(items_list)}). Displaying empty editor.\", icon=\"‚ö†Ô∏è\")\n",
        "                 items_list = []\n",
        "            try:\n",
        "                processed_items = []\n",
        "                required_item_keys = ['description', 'quantity', 'price']\n",
        "                for item in items_list:\n",
        "                    if isinstance(item, dict):\n",
        "                         processed_item = {key: item.get(key) for key in required_item_keys}\n",
        "                         processed_items.append(processed_item)\n",
        "                    else: st.warning(f\"Skipping invalid item data: {item}\", icon=\"‚ö†Ô∏è\")\n",
        "                items_df = pd.DataFrame(processed_items)\n",
        "                for col in required_item_keys:\n",
        "                     if col not in items_df.columns: items_df[col] = pd.NA\n",
        "                items_df['description'] = items_df['description'].astype(str).fillna('')\n",
        "                items_df['quantity'] = pd.to_numeric(items_df['quantity'], errors='coerce').fillna(0).astype(int)\n",
        "                items_df['price'] = pd.to_numeric(items_df['price'], errors='coerce').fillna(0.0).astype(float)\n",
        "                items_df = items_df[required_item_keys]\n",
        "            except Exception as df_err:\n",
        "                st.error(f\"Could not create/process DataFrame from items list: {df_err}.\", icon=\"‚ùå\")\n",
        "                items_df = pd.DataFrame(columns=required_item_keys)\n",
        "            edited_items_df = st.data_editor(\n",
        "                items_df, num_rows=\"dynamic\", column_config={\n",
        "                     \"quantity\": st.column_config.NumberColumn(\"Qty\", format=\"%d\", step=1, min_value=0),\n",
        "                     \"price\": st.column_config.NumberColumn(\"Price (VND)\", format=\"%.0f\", step=1.0, min_value=0.0),\n",
        "                     \"description\": st.column_config.TextColumn(\"Description\", width=\"large\", required=True)},\n",
        "                key=\"items_editor\", use_container_width=True)\n",
        "            form_data['items'] = edited_items_df.to_dict('records')\n",
        "\n",
        "            # ... (Form Submission Button and Logic - remain the same, call connect_to_gsheet and append_to_gsheet) ...\n",
        "            submit_button = st.form_submit_button(\n",
        "                 \"Confirm & Save to Google Sheet\", disabled=not gsheet_ready_for_export, use_container_width=True)\n",
        "            if submit_button:\n",
        "                if form_data.get('receipt_date'): form_data['receipt_date'] = form_data['receipt_date'].strftime('%Y-%m-%d')\n",
        "                else: form_data['receipt_date'] = ''\n",
        "                form_data['total_amount'] = form_data.get('total_amount', 0.0)\n",
        "                st.session_state.confirmed_data = form_data\n",
        "                st.write(\"Data confirmed. Attempting to save to Google Sheet...\")\n",
        "                sheet, _ = connect_to_gsheet()\n",
        "                if sheet:\n",
        "                    with st.spinner(\"Appending data to Google Sheet...\"):\n",
        "                        success = append_to_gsheet(sheet, st.session_state.confirmed_data)\n",
        "                        if success: st.success(f\"Data successfully appended to Google Sheet '{GOOGLE_SHEET_NAME}'!\", icon=\"‚úÖ\")\n",
        "                        else: st.error(\"Failed to save data to Google Sheet.\", icon=\"‚ùå\")\n",
        "                else: st.error(\"Cannot save data. Google Sheet connection failed.\", icon=\"‚ùå\")\n",
        "\n",
        "    elif run_extraction and not st.session_state.ocr_text:\n",
        "         st.warning(\"Please run OCR first to generate text for extraction.\", icon=\"‚ö†Ô∏è\")\n",
        "    elif not st.session_state.extracted_data:\n",
        "        st.info(\"Extracted data will appear here after running LLM extraction.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Launch app via ngrok tunnel\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "NGROK_AUTH_TOKEN = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"Ngrok auth token set.\")\n",
        "else:\n",
        "    print(\"Ngrok auth token not found in .env. Running without token.\")\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.run(['streamlit', 'run', '--server.port', '8501', '--server.headless=true', 'app.py'])\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "public_url = None\n",
        "try:\n",
        "    public_url = ngrok.connect(addr='8501', proto='http')\n",
        "    print(f\"üéâ Your Streamlit app should be available at: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error starting ngrok: {e}\")\n",
        "    print(\"   Streamlit might be running locally but ngrok tunnel failed.\")\n",
        "\n",
        "import time\n",
        "try:\n",
        "    while thread.is_alive():\n",
        "        time.sleep(60)\n",
        "    print(\"Streamlit thread seems to have stopped.\")\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nKeyboardInterrupt received. Shutting down...\")\n",
        "except Exception as e:\n",
        "    print(f\"Exception in keep-alive loop: {e}\")\n",
        "finally:\n",
        "    print(\"Closing ngrok tunnel...\")\n",
        "    if public_url:\n",
        "        try: ngrok.disconnect(public_url); print(\"Ngrok tunnel disconnected.\")\n",
        "        except Exception as ng_e: print(f\"Error disconnecting ngrok: {ng_e}\")\n",
        "    ngrok.kill()\n",
        "    print(\"Ngrok process killed.\")\n",
        "    print(\"Exiting keep-alive loop.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDrccgRbj8oV",
        "outputId": "36406371-a024-4d69-f1ff-4a60668848c7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok auth token set.\n",
            "üéâ Your Streamlit app should be available at: NgrokTunnel: \"https://654a-34-83-108-135.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "KeyboardInterrupt received. Shutting down...\n",
            "Closing ngrok tunnel...\n",
            "Error disconnecting ngrok: ngrok client exception, URLError: [Errno 111] Connection refused\n",
            "Ngrok process killed.\n",
            "Exiting keep-alive loop.\n"
          ]
        }
      ]
    }
  ]
}